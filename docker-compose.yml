# =============================================================================
# MY SELF-HOSTED AI KIT - Docker Compose Configuration
# =============================================================================
# Este archivo define todos los servicios necesarios para ejecutar un stack
# completo de herramientas de Inteligencia Artificial auto-hospedadas.
#
# SERVICIOS INCLUIDOS:
# - Ollama: Servidor de modelos de lenguaje local (LLMs)
# - Open WebUI: Interfaz web moderna para chat con IA
# - n8n: Plataforma de automatizaci√≥n de flujos de trabajo
# - PostgreSQL: Base de datos para n8n
# - Qdrant: Base de datos vectorial para embeddings
# - pgvector: Extensi√≥n de PostgreSQL para vectores
# =============================================================================

# =============================================================================
# CONFIGURACI√ìN COM√öN Y VARIABLES DE ENTORNO
# =============================================================================
# Configuraci√≥n compartida entre servicios para consistencia
x-common-env: &common-env
  # Configuraci√≥n de zona horaria
  TZ: ${TZ:-UTC}
  # Configuraci√≥n de usuario/grupo (para permisos de archivos)
  PUID: ${PUID:-1000}
  PGID: ${PGID:-1000}

# Configuraci√≥n de desarrollo vs producci√≥n
x-dev-config: &dev-config
  environment:
    - DEBUG=${DEBUG:-true}
    - LOG_LEVEL=${LOG_LEVEL:-debug}
  restart: "no"

x-prod-config: &prod-config
  environment:
    - DEBUG=${DEBUG:-false}
    - LOG_LEVEL=${LOG_LEVEL:-info}
  restart: unless-stopped

# =============================================================================
# VOL√öMENES PERSISTENTES
# =============================================================================
# Los vol√∫menes almacenan datos de forma persistente, sobreviviendo a reinicios
# y eliminaci√≥n de contenedores. Todos los datos importantes se guardan aqu√≠.
volumes:
  n8n_storage:        # Datos de n8n (workflows, credenciales, configuraciones)
  postgres_storage:   # Base de datos PostgreSQL principal
  ollama_storage:     # Modelos de IA descargados (¬°pueden ser muy grandes!)
  qdrant_storage:     # Base de datos vectorial Qdrant
  pgvector_data:      # Base de datos PostgreSQL con extensi√≥n vectorial
  open_webui_storage: # Datos de Open WebUI (chats, configuraciones)
  n8n_data:           # Datos de importaci√≥n/exportaci√≥n de n8n
  shared_data:        # Datos compartidos entre servicios
  # Nuevos vol√∫menes para mejoras
  prometheus_data:    # Datos de m√©tricas de Prometheus
  grafana_data:       # Datos de Grafana
  alertmanager_data:  # Datos de AlertManager
  backup_data:        # Datos de respaldos autom√°ticos
  # Vol√∫menes para nuevas mejoras
  redis_data:         # Cache Redis
  jenkins_data:       # Datos de Jenkins CI/CD
  haproxy_data:       # Configuraci√≥n de HAProxy
  keycloak_data:      # Datos de Keycloak
  modsecurity_data:   # Reglas de ModSecurity
  cadvisor_data:      # Datos de cAdvisor
  node_exporter_data: # Datos de Node Exporter
  postgres_exporter_data: # Datos de PostgreSQL Exporter
  # Vol√∫menes para mejoras de persistencia
  config_data:        # Configuraciones persistentes (Prometheus, Grafana, AlertManager, HAProxy, ModSecurity)
  ssl_certs_data:     # Certificados SSL/TLS generados
  logs_data:          # Logs consolidados de todos los servicios
  grafana_provisioning_data: # Dashboards y datasources provisionados de Grafana
  prometheus_rules_data: # Reglas de alertas personalizadas de Prometheus

# =============================================================================
# REDES
# =============================================================================
# Define redes personalizadas para separar frontend y backend
networks:
  genai-network:
    driver: bridge
    name: genai-network
  frontend-network:
    driver: bridge
    name: frontend-network
  backend-network:
    driver: bridge
    name: backend-network
    internal: true  # Solo comunicaci√≥n interna
  monitoring-network:
    driver: bridge
    name: monitoring-network
  security-network:
    driver: bridge
    name: security-network
    internal: true

# =============================================================================
# PLANTILLAS DE SERVICIOS (YAML Anchors)
# =============================================================================
# Estas plantillas definen configuraciones comunes que se reutilizan en
# m√∫ltiples servicios para evitar duplicaci√≥n de c√≥digo.

# Plantilla para servicios n8n (n8n es una plataforma de automatizaci√≥n)
x-n8n: &service-n8n
  #image: n8nio/n8n:latest
  # NOTA: Usar versi√≥n espec√≠fica en lugar de 'latest' para evitar actualizaciones inesperadas
  # Actualizar manualmente despu√©s de hacer backup y probar workflows
  # Actualizaci√≥n gradual completada: 1.101.2 -> 1.110.1 -> 1.122.5
  image: docker.n8n.io/n8nio/n8n:1.122.5  # Versi√≥n m√°s reciente (actualizado el 2025-12-07)
  networks: ['genai-network']     # Conecta a nuestra red personalizada
  environment:
    - DB_TYPE=${N8N_DB_TYPE:-postgresdb}          # Tipo de base de datos (PostgreSQL)
    - DB_POSTGRESDB_HOST=${N8N_DB_HOST:-postgres} # Host de la base de datos
    - DB_POSTGRESDB_USER=${POSTGRES_USER}     # Usuario de BD (desde .env)
    - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD} # Contrase√±a de BD (desde .env)
    - N8N_DIAGNOSTICS_ENABLED=${N8N_DIAGNOSTICS_ENABLED:-false}           # Desactiva telemetr√≠a
    - N8N_PERSONALIZATION_ENABLED=${N8N_PERSONALIZATION_ENABLED:-false}       # Desactiva personalizaci√≥n
    - N8N_ENCRYPTION_KEY                      # Clave para encriptar datos
    - N8N_USER_MANAGEMENT_JWT_SECRET          # Clave para tokens JWT
    - OLLAMA_HOST=${OLLAMA_HOST_INTERNAL:-ollama}:${OLLAMA_PORT_INTERNAL:-11434}                # Conecta con Ollama
  env_file:
    - .env                                    # Carga variables desde archivo .env
  # Configuraci√≥n de logging mejorada
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"
  # L√≠mites de recursos para evitar consumo excesivo
  deploy:
    resources:
      limits:
        cpus: '4.0'
        memory: 4G
      reservations:
        cpus: '1.0'
        memory: 1G

# Plantilla para servicios Ollama (servidor de modelos de IA)
x-ollama: &service-ollama
  image: ollama/ollama:latest     # Imagen oficial de Ollama
  container_name: ollama
  networks: ['genai-network']
  restart: unless-stopped         # Reinicia autom√°ticamente si falla
  ports:
    - "${PORT_OLLAMA_HOST:-11434}:${PORT_OLLAMA_CONTAINER:-11434}"
  volumes:
    - ollama_storage:/root/.ollama # Almacena modelos descargados
  healthcheck:                    # Verifica que el servicio est√© funcionando
    test: ["CMD-SHELL", "pgrep -f ollama || exit 1"]
    interval: 10s                 # Verifica cada 10 segundos
    timeout: 5s                   # Timeout de 5 segundos
    retries: 5                    # Reintenta 5 veces antes de marcar como unhealthy
    start_period: 10s             # Espera 10 segundos antes de empezar healthchecks
  # Configuraci√≥n de logging mejorada
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"
  # L√≠mites de recursos (Ollama puede consumir mucha RAM)
  deploy:
    resources:
      limits:
        cpus: '6.0'
        memory: 32G
      reservations:
        cpus: '2.0'
        memory: 8G

# Plantilla para inicializaci√≥n de modelos de Ollama
# Este servicio descarga autom√°ticamente los modelos de IA al iniciar
x-init-ollama: &init-ollama
  image: ollama/ollama:latest
  networks: ['genai-network']
  container_name: ollama-pull-llama
  volumes:
    - ollama_storage:/root/.ollama # Comparte el mismo volumen que ollama
  entrypoint: /bin/sh              # Usa shell para ejecutar comandos
  environment:
    - OLLAMA_HOST=${OLLAMA_HOST_INTERNAL:-ollama}:${OLLAMA_PORT_INTERNAL:-11434}     # Conecta con el servicio ollama
  command:
    - "-c"
    - |
      set -e                       # Termina si cualquier comando falla
      echo "Descargando llama3.2..."
      ollama pull llama3.2 || { echo "‚ùå Fall√≥ llama3.2"; exit 1; }

      echo "Descargando llama3.3..."
      ollama pull llama3.3 || { echo "‚ùå Fall√≥ llama3.3"; exit 1; }

      echo "Descargando all-minilm..."
      ollama pull all-minilm || { echo "‚ùå Fall√≥ all-minilm"; exit 1; }

      #echo "Descargando all-minilm:33m..."
      #ollama pull all-minilm:33m || { echo "‚ùå Fall√≥ all-minilm:33m"; exit 1; }

      echo "Descargando deepseek-r1:14b..."
      ollama pull deepseek-r1:14b || { echo "‚ùå Fall√≥ deepseek"; exit 1; }

      echo "Descargando nomic-embed-text..."
      ollama pull nomic-embed-text || { echo "‚ùå Fall√≥ nomic-embed-text"; exit 1; }

      echo "‚úÖ Todos los modelos fueron descargados correctamente"
  # Configuraci√≥n de logging
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"

# =============================================================================
# SERVICIOS PRINCIPALES
# =============================================================================

services:
  # Inicializador de base de datos para Keycloak
  postgres-init:
    image: postgres:16-alpine
    container_name: postgres-init
    profiles: ["security"]
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - postgres_storage:/var/lib/postgresql/data
      - ./scripts/init-keycloak-db.sql:/docker-entrypoint-initdb.d/init-keycloak-db.sql
    networks:
      - genai-network
    command: postgres -c 'max_connections=${POSTGRES_MAX_CONNECTIONS:-200}'
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -h localhost -U ${POSTGRES_USER} -d ${POSTGRES_DB}']
      interval: 5s
      timeout: 5s
      retries: 10
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G

  postgres:
    image: postgres:16-alpine      # PostgreSQL 16 con Alpine Linux (m√°s ligero)
    hostname: ${POSTGRES_HOSTNAME:-postgres}
    container_name: postgres
    networks: ['genai-network']
    restart: unless-stopped
    environment:
      - POSTGRES_USER              # Usuario de BD (desde .env)
      - POSTGRES_PASSWORD          # Contrase√±a de BD (desde .env)
      - POSTGRES_DB                # Nombre de BD (desde .env)
      # Configuraci√≥n para prevenir transacciones pendientes y locks
      - POSTGRES_INITDB_ARGS=-E UTF8 --locale=C
    volumes:
      - postgres_storage:/var/lib/postgresql/data  # Datos persistentes
    # Tiempo de gracia para shutdown limpio (30 segundos)
    stop_grace_period: 30s
    # Comando con configuraci√≥n para manejar mejor los shutdowns
    command: >
      postgres
      -c shared_buffers=256MB
      -c max_connections=${POSTGRES_MAX_CONNECTIONS:-200}
      -c statement_timeout=30000
      -c idle_in_transaction_session_timeout=60000
      -c lock_timeout=30000
    healthcheck:                   # Verifica que PostgreSQL est√© listo
      test: ['CMD-SHELL', 'pg_isready -h localhost -U ${POSTGRES_USER} -d ${POSTGRES_DB}']
      interval: 5s
      timeout: 5s
      retries: 10
    # Configuraci√≥n de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # L√≠mites de recursos
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G

  # Base de datos PostgreSQL con extensi√≥n vectorial (para embeddings)
  pgvector:
    image: ankane/pgvector         # PostgreSQL con extensi√≥n pgvector
    container_name: pgvector
    networks: ['genai-network']
    environment:
      POSTGRES_USER: ${PGVECTOR_USER:-user}
      POSTGRES_PASSWORD: ${PGVECTOR_PASSWORD:-password}
      POSTGRES_DB: ${PGVECTOR_DB:-pgvector_db}
    ports:
      - "${PORT_PGVECTOR_HOST:-5433}:${PORT_PGVECTOR_CONTAINER:-5432}"
    restart: unless-stopped
    volumes:
      - pgvector_data:/var/lib/postgresql/data
    # Configuraci√≥n de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # L√≠mites de recursos
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G

  # Interfaz web moderna para chat con IA
  open-webui:
    image: ghcr.io/open-webui/open-webui:0.6.41 # Versi√≥n m√°s reciente - probando mejoras OIDC
    container_name: open-webui
    profiles: ["chat-ai"]          # Perfil de chat con IA (requiere --profile security para Keycloak)
    ports:
      - "${PORT_OPEN_WEBUI_HOST:-3000}:${PORT_OPEN_WEBUI_CONTAINER:-8080}"
    environment:
      # OLLAMA_BASE_URL: URL interna para conectar con Ollama desde el contenedor
      # IMPORTANTE: Si OLLAMA_URL_INTERNAL est√° vac√≠a en .env, debe tener un valor o no estar definida
      # Si est√° definida pero vac√≠a, Docker Compose la pasa como cadena vac√≠a y ${VAR:-default} no funciona
      - OLLAMA_BASE_URL=${OLLAMA_URL_INTERNAL:-http://ollama:11434}
      - USER_AGENT=${OPEN_WEBUI_USER_AGENT:-OpenWebUI/0.6.13}
      - CORS_ALLOW_ORIGIN=${OPEN_WEBUI_URL_PUBLIC:-http://localhost:3000}
      # Configuraci√≥n de usuarios y acceso
      - ENABLE_SIGNUP=${OPEN_WEBUI_ENABLE_SIGNUP:-true}  # Permitir registro de usuarios
      - ENABLE_LOGIN_FORM=${OPEN_WEBUI_ENABLE_LOGIN_FORM:-true}  # Permitir login con formulario
      # Configuraci√≥n OIDC/OAuth con Keycloak
      - ENABLE_OAUTH_SSO=${OPEN_WEBUI_ENABLE_OAUTH_SSO:-true}
      - ENABLE_OAUTH_SIGNUP=${OPEN_WEBUI_ENABLE_OAUTH_SIGNUP:-true}  # Permitir registro autom√°tico de usuarios OAuth
      - OAUTH_CLIENT_ID=${OPEN_WEBUI_OAUTH_CLIENT_ID:-open-webui}
      - OAUTH_CLIENT_SECRET=${OPEN_WEBUI_OAUTH_CLIENT_SECRET}
      - OAUTH_PROVIDER_NAME=${OPEN_WEBUI_OAUTH_PROVIDER_NAME:-Keycloak}
      # Configuraci√≥n OIDC - LIMITACI√ìN CONOCIDA DE OPEN WEBUI
      # Problema: Open WebUI usa URLs del discovery document (localhost:8080) 
      # en lugar de las URLs expl√≠citas (keycloak:8080), causando error 405
      # Esto es una limitaci√≥n de Open WebUI que no respeta URLs expl√≠citas
      # cuando hay un discovery document configurado
      - OPENID_ENABLED=${OPEN_WEBUI_OAUTH_ENABLED:-true}  # OpenID usa variables OAUTH_ (consolidado seg√∫n documentaci√≥n)
      - OPENID_CLIENT_ID=${OPEN_WEBUI_OAUTH_CLIENT_ID:-open-webui}  # OpenID usa variables OAUTH_ (consolidado seg√∫n documentaci√≥n)
      - OPENID_CLIENT_SECRET=${OPEN_WEBUI_OAUTH_CLIENT_SECRET}  # OpenID usa variables OAUTH_ (consolidado seg√∫n documentaci√≥n)
      # OPENID_PROVIDER_URL necesario para que aparezca el bot√≥n
      - OPENID_PROVIDER_URL=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/.well-known/openid-configuration
      - OPENID_REDIRECT_URI=${OPEN_WEBUI_URL_PUBLIC:-http://localhost:3000}/oauth/oidc/callback
      # URLs expl√≠citas configuradas pero Open WebUI las ignora cuando hay discovery document
      - OPENID_AUTHORIZATION_ENDPOINT=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/auth
      - OPENID_TOKEN_ENDPOINT=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/token
      - OPENID_USERINFO_ENDPOINT=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/userinfo
      - OPENID_ISSUER=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}
      - OPENID_SCOPES=${OPEN_WEBUI_OAUTH_SCOPES:-openid profile email}  # OpenID usa variables OAUTH_ (consolidado seg√∫n documentaci√≥n)
      - OPENID_SIGN_OUT_REDIRECT_URL=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/logout
    volumes:
      - open_webui_storage:/app/backend/data   # Datos persistentes
      #- /mnt/e/docker/app/open-webui/backend/data:/app/backend/data  # Montaje local (comentado)
    networks:
      - genai-network
    depends_on:
      keycloak:
        condition: service_healthy     # Espera a que Keycloak est√© listo (requiere --profile security)
      # NOTA: Ollama est√° en perfiles (ollama-gpu, ollama-cpu, etc.) - no puede depender expl√≠citamente
      # Open WebUI puede iniciar sin Ollama, pero no funcionar√° completamente hasta que est√© listo
    healthcheck:                   # Verifica que Open WebUI est√© funcionando
      test: ["CMD", "curl", "-f", "http://localhost:8080/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5
    # Configuraci√≥n de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # L√≠mites de recursos
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G
#    depends_on:
#      ollama-gpu:
#        condition: service_healthy

  # Servicio de importaci√≥n de datos para n8n (se ejecuta una vez al inicio)
  n8n-import:
    <<: *service-n8n               # Usa la plantilla n8n
    hostname: n8n-import
    container_name: n8n-import
    networks: ['genai-network']
    entrypoint: /bin/sh            # Usa shell para ejecutar comandos de importaci√≥n
    command:
      - "-c"
      - "n8n import:credentials --separate --input=/data/credentials && n8n import:workflow --separate --input=/data/workflows"
    volumes:
      - n8n_data:/data             # Datos de importaci√≥n/exportaci√≥n
    depends_on:
      postgres:
        condition: service_healthy # Espera a que PostgreSQL est√© listo
    healthcheck:                   # Verifica que n8n-import est√© funcionando
      test: ["CMD", "curl", "-f", "http://n8n:5678/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Servicio principal de n8n (plataforma de automatizaci√≥n)
  n8n:
    <<: *service-n8n               # Usa la plantilla n8n
    hostname: n8n
    container_name: n8n
    profiles: ["automation"]        # Perfil de automatizaci√≥n (requiere --profile security para Keycloak)
    restart: unless-stopped
    ports:
      - "${PORT_N8N_HOST:-5678}:${PORT_N8N_CONTAINER:-5678}"
    environment:
      - N8N_RUNNERS_ENABLED=${N8N_RUNNERS_ENABLED:-true}
      - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=${N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS:-true}
      # Configuraci√≥n OIDC/OAuth con Keycloak
      - N8N_AUTH_TYPE=${N8N_AUTH_TYPE:-oidc}
      - N8N_OIDC_ISSUER=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}
      - N8N_OIDC_CLIENT_ID=${N8N_OIDC_CLIENT_ID:-n8n}
      - N8N_OIDC_CLIENT_SECRET=${N8N_OIDC_CLIENT_SECRET:-change_me_n8n_client_secret}
      # URLs expl√≠citas - authorization usa localhost (navegador), token/userinfo usan keycloak (interno)
      - N8N_OIDC_AUTHORIZATION_URL=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/auth
      - N8N_OIDC_TOKEN_URL=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/token
      - N8N_OIDC_USER_INFO_URL=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/userinfo
      - N8N_OIDC_REDIRECT_URI=${N8N_URL_PUBLIC:-http://localhost:5678}/rest/oauth2-credential/callback
      - N8N_OIDC_SCOPES=${N8N_OIDC_SCOPES:-openid profile email}
      - N8N_OIDC_DISPLAY_NAME=${N8N_OIDC_DISPLAY_NAME:-Keycloak}
    volumes:
      - n8n_storage:/home/node/.n8n    # Datos persistentes de n8n
      - n8n_data:/data                 # Datos de importaci√≥n/exportaci√≥n
      - shared_data:/data/shared       # Datos compartidos
    depends_on:
      postgres:
        condition: service_healthy     # Espera a que PostgreSQL est√© listo
      n8n-import:
        condition: service_completed_successfully  # Espera a que termine la importaci√≥n
      keycloak:
        condition: service_healthy     # Espera a que Keycloak est√© listo (requiere --profile security)
    healthcheck:                       # Verifica que n8n est√© funcionando
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:5678/healthz || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Base de datos vectorial Qdrant (para embeddings y b√∫squeda sem√°ntica)
  qdrant:
    image: qdrant/qdrant
    hostname: qdrant
    container_name: qdrant
    networks: ['genai-network']
    restart: unless-stopped
    ports:
      - "${PORT_QDRANT_HOST:-6333}:${PORT_QDRANT_CONTAINER:-6333}"
    volumes:
      - qdrant_storage:/qdrant/storage  # Datos persistentes
    healthcheck:                   # Verifica que Qdrant est√© funcionando
      test: ["CMD-SHELL", "for pid in /proc/*/comm; do [ -f \"$$pid\" ] && grep -q qdrant \"$$pid\" 2>/dev/null && exit 0; done; exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    # Configuraci√≥n de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # L√≠mites de recursos
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G

  # =============================================================================
  # SERVICIOS DE OLLAMA (DIFERENTES PERFILES)
  # =============================================================================
  # Estos servicios usan perfiles para activar solo uno seg√∫n el hardware disponible

  # Perfil CPU: Ollama usando solo CPU (m√°s lento pero funciona en cualquier m√°quina)
  ollama-cpu:
    profiles: ["cpu"]              # Solo se activa con --profile cpu
    <<: *service-ollama            # Usa la plantilla ollama

  # Perfil GPU NVIDIA: Ollama con aceleraci√≥n GPU NVIDIA
  ollama-gpu:
    profiles: ["gpu-nvidia"]       # Solo se activa con --profile gpu-nvidia
    <<: *service-ollama            # Usa la plantilla ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia        # Usa driver NVIDIA
              count: 1              # Usa 1 GPU
              capabilities: [gpu]   # Habilita capacidades GPU

  # Perfil GPU AMD: Ollama con aceleraci√≥n GPU AMD
  ollama-gpu-amd:
    profiles: ["gpu-amd"]          # Solo se activa con --profile gpu-amd
    <<: *service-ollama
    image: ollama/ollama:rocm      # Imagen con soporte ROCm (AMD)
    devices:
      - "/dev/kfd"                 # Dispositivo AMD GPU
      - "/dev/dri"                 # Dispositivo de renderizado



  # =============================================================================
  # SERVICIOS DE INICIALIZACI√ìN DE MODELOS (DIFERENTES PERFILES)
  # =============================================================================
  # Estos servicios descargan los modelos de IA seg√∫n el perfil activado

  # Descarga de modelos para CPU
  # ollama-pull-llama-cpu:
  #   profiles: ["cpu"]
  #   <<: *init-ollama               # Usa la plantilla de inicializaci√≥n
  #   depends_on:
  #     - ollama-cpu                 # Espera a que ollama-cpu est√© listo

  # Descarga de modelos para GPU NVIDIA
  # ollama-pull-llama-gpu:
  #   profiles: ["gpu-nvidia"]
  #   <<: *init-ollama               # Usa la plantilla de inicializaci√≥n
  #   depends_on:
  #     - ollama-gpu                 # Espera a que ollama-gpu est√© listo

  # Descarga de modelos para GPU AMD
  # ollama-pull-llama-gpu-amd:
  #   profiles: [gpu-amd]
  #   <<: *init-ollama               # Usa la plantilla de inicializaci√≥n
  #   image: ollama/ollama:rocm      # Imagen con soporte ROCm
  #   depends_on:
  #    - ollama-gpu-amd              # Espera a que ollama-gpu-amd est√© listo

  # =============================================================================
  # SERVICIOS DE MONITOREO Y MANTENIMIENTO (OPCIONALES)
  # =============================================================================
  # Estos servicios ayudan a monitorear y mantener el stack

  # Prometheus - Recolector de m√©tricas
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    profiles: ["monitoring"]
    ports:
      - "${PORT_PROMETHEUS_HOST:-9090}:${PORT_PROMETHEUS_CONTAINER:-9090}"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus_rules_data:/etc/prometheus/rules/custom:ro  # Reglas personalizadas persistentes
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - monitoring-network
      - genai-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

  # Grafana - Dashboards y visualizaci√≥n
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    profiles: ["monitoring"]
    ports:
      - "${PORT_GRAFANA_HOST:-3001}:${PORT_GRAFANA_CONTAINER:-3000}"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./monitoring/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/config/grafana.ini:/etc/grafana/grafana.ini:ro
      # Volumen para dashboards personalizados creados por usuarios
      - grafana_provisioning_data:/var/lib/grafana/dashboards/custom:ro
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=${GRAFANA_USERS_ALLOW_SIGN_UP:-false}
      - GF_AUTH_GENERIC_OAUTH_ENABLED=${GRAFANA_AUTH_GENERIC_OAUTH_ENABLED:-true}
      - GF_AUTH_GENERIC_OAUTH_NAME=${GRAFANA_OAUTH_NAME:-Keycloak}
      - GF_AUTH_GENERIC_OAUTH_CLIENT_ID=${GRAFANA_OAUTH_CLIENT_ID:-grafana}
      - GF_AUTH_GENERIC_OAUTH_CLIENT_SECRET=${GRAFANA_OAUTH_CLIENT_SECRET}
      - GF_AUTH_GENERIC_OAUTH_SCOPES=${GRAFANA_OAUTH_SCOPES:-openid profile email}
      # AUTH_URL debe usar localhost porque el navegador del usuario necesita acceder
      - GF_AUTH_GENERIC_OAUTH_AUTH_URL=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/auth
      # TOKEN_URL y API_URL pueden usar keycloak:8080 porque Grafana las llama desde dentro del contenedor
      - GF_AUTH_GENERIC_OAUTH_TOKEN_URL=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/token
      - GF_AUTH_GENERIC_OAUTH_API_URL=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/userinfo
      - GF_AUTH_GENERIC_OAUTH_SKIP_ORG_ROLE_SYNC=${GRAFANA_SKIP_ORG_ROLE_SYNC:-true}  # Necesario: Keycloak devuelve realm roles del usuario admin que Grafana intenta sincronizar
      # SIGNOUT_REDIRECT_URL debe usar localhost porque el navegador del usuario necesita acceder
      - GF_AUTH_SIGNOUT_REDIRECT_URL=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/logout
      - GF_SERVER_ROOT_URL=${GRAFANA_URL_PUBLIC:-http://localhost:3001}
      - GF_USERS_AUTO_LOGIN=${GRAFANA_USERS_AUTO_LOGIN:-false}
      - GF_AUTH_DISABLE_LOGIN_FORM=${GRAFANA_AUTH_DISABLE_LOGIN_FORM:-true}  # Solo Keycloak OAuth (m√°s seguro)
    networks:
      - monitoring-network
      - genai-network
    depends_on:
      prometheus:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

  # AlertManager - Gesti√≥n de alertas
  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    profiles: ["monitoring"]
    ports:
      - "${PORT_ALERTMANAGER_HOST:-9093}:${PORT_ALERTMANAGER_CONTAINER:-9093}"
    volumes:
      - ./monitoring/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    networks:
      - monitoring-network
      - genai-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M

  # Servicio de backup autom√°tico
  backup:
    image: alpine:latest
    container_name: backup
    profiles: ["monitoring"]       # Solo se activa con --profile monitoring
    volumes:
      - n8n_storage:/data/n8n:ro
      - postgres_storage:/data/postgres:ro
      - backup_data:/backups
    command: |
      sh -c "
      apk add --no-cache tar
      while true; do
        tar -czf /backups/backup-$$(date +%Y%m%d-%H%M%S).tar.gz -C /data .
        sleep 86400
      done
      "
    # Configuraci√≥n de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # L√≠mites de recursos
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M

  # Servicio de herramientas de desarrollo
  dev-tools:
    image: alpine:latest
    container_name: dev-tools
    profiles: ["dev"]              # Solo se activa con --profile dev
    volumes:
      - .:/workspace
    working_dir: /workspace
    command: sh -c "apk add --no-cache curl jq && tail -f /dev/null"
    # Configuraci√≥n de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # L√≠mites de recursos
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Node Exporter - M√©tricas del host
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    profiles: ["monitoring"]
    ports:
      - "${PORT_NODE_EXPORTER_HOST:-9100}:${PORT_NODE_EXPORTER_CONTAINER:-9100}"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - monitoring-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9100/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # cAdvisor - M√©tricas de contenedores
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    profiles: ["monitoring"]
    ports:
      - "${PORT_CADVISOR_HOST:-8082}:${PORT_CADVISOR_CONTAINER:-8080}"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro  # Necesario para descubrir contenedores
    networks:
      - monitoring-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M

  # PostgreSQL Exporter - M√©tricas de PostgreSQL
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: postgres-exporter
    profiles: ["monitoring"]
    environment:
      DATA_SOURCE_NAME: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?sslmode=disable"
    ports:
      - "${PORT_POSTGRES_EXPORTER_HOST:-9187}:${PORT_POSTGRES_EXPORTER_CONTAINER:-9187}"
    networks:
      - monitoring-network
      - genai-network  # Necesario para conectarse a PostgreSQL
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9187/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # =============================================================================
  # SERVICIOS DE INFRAESTRUCTURA
  # =============================================================================
  # Servicios que mejoran el rendimiento y escalabilidad

  # Redis - Cache y sesiones
  redis:
    image: redis:alpine
    container_name: redis
    profiles: ["infrastructure"]
    ports:
      - "${PORT_REDIS_HOST:-6379}:${PORT_REDIS_CONTAINER:-6379}"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.25'
          memory: 512M

  # HAProxy - Load Balancer
  haproxy:
    image: haproxy:latest
    container_name: haproxy
    profiles: ["infrastructure"]
    ports:
      - "${PORT_HAPROXY_HTTP_HOST:-80}:${PORT_HAPROXY_HTTP_CONTAINER:-80}"
      - "${PORT_HAPROXY_HTTPS_HOST:-443}:${PORT_HAPROXY_HTTPS_CONTAINER:-443}"
    volumes:
      - ./haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
      - haproxy_data:/var/lib/haproxy
    networks:
      - frontend-network
      - backend-network
      - genai-network
      - monitoring-network  # Agregado para poder resolver Grafana y Prometheus
    depends_on:
      open-webui:
        condition: service_healthy
      n8n:
        condition: service_healthy
      grafana:
        condition: service_healthy  # Esperar a que Grafana est√© listo
      prometheus:
        condition: service_healthy  # Esperar a que Prometheus est√© listo
    healthcheck:
      test: ["CMD", "haproxy", "-c", "-f", "/usr/local/etc/haproxy/haproxy.cfg"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M



  # =============================================================================
  # SERVICIOS DE SEGURIDAD Y AUTENTICACI√ìN
  # =============================================================================
  # Servicios para mejorar la seguridad del stack

  # Keycloak - Autenticaci√≥n centralizada
  keycloak:
    image: quay.io/keycloak/keycloak:latest
    container_name: keycloak
    profiles: ["security"]
    environment:
      - KEYCLOAK_ADMIN=${KEYCLOAK_ADMIN_USER:-admin}
      - KEYCLOAK_ADMIN_PASSWORD=${KEYCLOAK_ADMIN_PASSWORD:-admin}
      - KC_DB=${KEYCLOAK_DB_TYPE:-postgres}
      - KC_DB_URL=jdbc:postgresql://${POSTGRES_HOST_INTERNAL:-postgres}:${POSTGRES_PORT_INTERNAL:-5432}/${KEYCLOAK_DB_NAME:-keycloak}?connectTimeout=10&socketTimeout=60
      - KC_DB_USERNAME=${POSTGRES_USER}
      - KC_DB_PASSWORD=${POSTGRES_PASSWORD}
      # Configuraci√≥n de pool de conexiones para prevenir transacciones pendientes
      # IMPORTANTE: Reducir INITIAL_SIZE para evitar m√∫ltiples conexiones compitiendo por el lock al inicio
      - KC_DB_POOL_INITIAL_SIZE=${KEYCLOAK_DB_POOL_INITIAL_SIZE:-2}
      - KC_DB_POOL_MIN_SIZE=${KEYCLOAK_DB_POOL_MIN_SIZE:-2}
      - KC_DB_POOL_MAX_SIZE=${KEYCLOAK_DB_POOL_MAX_SIZE:-20}
      - KC_HOSTNAME=${HOSTNAME_PUBLIC:-localhost}
      - KC_HOSTNAME_PORT=${PORT_KEYCLOAK_HOST:-8080}
      - KC_HOSTNAME_STRICT=${KEYCLOAK_HOSTNAME_STRICT:-false}
      - KC_HTTP_ENABLED=${KEYCLOAK_HTTP_ENABLED:-true}
      - KC_HEALTH_ENABLED=${KEYCLOAK_HEALTH_ENABLED:-true}
      # Configuraci√≥n para cookies en contexto HTTP (no seguro)
      - KC_HTTP_RELATIVE_PATH=${KEYCLOAK_HTTP_RELATIVE_PATH:-/}
      - KC_PROXY=${KEYCLOAK_PROXY:-edge}
      - KC_PROXY_ADDRESS_FORWARDING=${KEYCLOAK_PROXY_ADDRESS_FORWARDING:-true}
    ports:
      - "${PORT_KEYCLOAK_HOST:-8080}:${PORT_KEYCLOAK_CONTAINER:-8080}"
    volumes:
      - keycloak_data:/opt/keycloak/data
    networks:
      - security-network
      - backend-network
      - genai-network
    depends_on:
      postgres:
        condition: service_healthy
      keycloak-db-init:
        condition: service_completed_successfully
    # Tiempo de gracia para shutdown limpio (30 segundos)
    stop_grace_period: 30s
    command: start-dev --http-enabled=true --hostname-strict=false
    healthcheck:
      # Keycloak health check: verificar que el proceso est√© corriendo Y que el puerto responda
      # Keycloak no tiene curl/wget, pero podemos verificar:
      # 1. Que el proceso keycloak est√© corriendo (verificaci√≥n principal)
      # 2. Que el puerto 8080 responda a conexiones TCP (verificaci√≥n secundaria)
      # Usamos verificaci√≥n simple pero confiable sin dependencias externas
      test: ["CMD-SHELL", "test -f /proc/1/cmdline && cat /proc/1/cmdline | grep -q keycloak && /bin/sh -c 'exec 3<>/dev/tcp/localhost/8080 2>/dev/null && echo -e \"GET / HTTP/1.1\\r\\nHost: localhost\\r\\nConnection: close\\r\\n\\r\\n\" >&3 && head -1 <&3 | grep -q \"HTTP\"' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Inicializador de BD de Keycloak - Crea BD ANTES de que Keycloak inicie
  keycloak-db-init:
    image: postgres:16-alpine
    container_name: keycloak-db-init
    profiles: ["security"]
    networks:
      - genai-network
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB:-postgres}
      - KEYCLOAK_DB_NAME=${KEYCLOAK_DB_NAME:-keycloak}
    entrypoint: /bin/sh
    command:
      - "-c"
      - |
        set -e
        echo "üîß Verificando base de datos de Keycloak..."
        echo ""
        
        # Esperar a que PostgreSQL est√© listo
        until PGPASSWORD="$${POSTGRES_PASSWORD}" psql -h postgres -U "$${POSTGRES_USER}" -d "$${POSTGRES_DB}" -c "SELECT 1;" > /dev/null 2>&1; do
          echo "   ‚è≥ Esperando a que PostgreSQL est√© listo..."
          sleep 2
        done
        
        # Verificar si la BD existe
        DB_EXISTS=$$(PGPASSWORD="$${POSTGRES_PASSWORD}" psql -h postgres -U "$${POSTGRES_USER}" -d "$${POSTGRES_DB}" -tAc "SELECT 1 FROM pg_database WHERE datname = '$${KEYCLOAK_DB_NAME}';" 2>/dev/null || echo "0")
        
        if [ "$$DB_EXISTS" != "1" ]; then
          echo "   ‚úÖ Creando base de datos '$${KEYCLOAK_DB_NAME}'..."
          PGPASSWORD="$${POSTGRES_PASSWORD}" psql -h postgres -U "$${POSTGRES_USER}" -d "$${POSTGRES_DB}" -c "CREATE DATABASE $${KEYCLOAK_DB_NAME} OWNER $${POSTGRES_USER};" 2>/dev/null || true
          echo "   ‚úÖ Base de datos creada (Keycloak crear√° la estructura autom√°ticamente)"
        else
          echo "   ‚úÖ Base de datos '$${KEYCLOAK_DB_NAME}' ya existe"
        fi
        echo ""
        echo "‚úÖ Base de datos lista para Keycloak"
    depends_on:
      postgres:
        condition: service_healthy
    restart: "no"  # Solo se ejecuta una vez
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Inicializador de clientes Keycloak - Crea clientes OIDC DESPU√âS de que Keycloak est√© listo
  keycloak-init:
    image: alpine:latest
    container_name: keycloak-init
    profiles: ["security"]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - genai-network
      - security-network
    environment:
      - KEYCLOAK_ADMIN_USER=${KEYCLOAK_ADMIN_USER:-admin}
      - KEYCLOAK_ADMIN_PASSWORD=${KEYCLOAK_ADMIN_PASSWORD:-admin}
      - KEYCLOAK_REALM=${KEYCLOAK_REALM:-master}
      - GRAFANA_URL_PUBLIC=${GRAFANA_URL_PUBLIC:-http://localhost:3001}
      - N8N_URL_PUBLIC=${N8N_URL_PUBLIC:-http://localhost:5678}
      - OPEN_WEBUI_URL_PUBLIC=${OPEN_WEBUI_URL_PUBLIC:-http://localhost:3000}
      - JENKINS_URL_PUBLIC=${JENKINS_URL_PUBLIC:-http://localhost:8081}
      # Secrets para clientes OIDC
      - GRAFANA_OAUTH_CLIENT_SECRET=${GRAFANA_OAUTH_CLIENT_SECRET}
      - N8N_OIDC_CLIENT_SECRET=${N8N_OIDC_CLIENT_SECRET}
      - OPEN_WEBUI_OAUTH_CLIENT_SECRET=${OPEN_WEBUI_OAUTH_CLIENT_SECRET}
      - JENKINS_OIDC_CLIENT_SECRET=${JENKINS_OIDC_CLIENT_SECRET}
    entrypoint: /bin/sh
    command:
      - "-c"
      - |
        set -e
        echo "üîß Creando clientes OIDC de Keycloak..."
        echo ""
        
        # Instalar dependencias necesarias
        apk add --no-cache docker-cli curl bash
        
        # Esperar a que Keycloak est√© completamente listo (healthcheck + endpoint ready)
        echo "‚è≥ Esperando a que Keycloak est√© listo..."
        MAX_WAIT=120  # Reducido a 2 minutos (suficiente para Keycloak)
        ELAPSED=0
        KEYCLOAK_READY=0
        
        while [ $$ELAPSED -lt $$MAX_WAIT ]; do
          # Verificar si Keycloak est√° healthy
          KEYCLOAK_STATUS=$$(docker ps --filter "name=keycloak" --format "{{.Status}}" 2>/dev/null || echo "")
          if echo "$$KEYCLOAK_STATUS" | grep -q "healthy"; then
            # Si est√° healthy, intentar verificar el endpoint (m√°ximo 3 intentos)
            for i in 1 2 3; do
              if curl -sf --max-time 5 http://keycloak:8080/health/ready > /dev/null 2>&1; then
                echo "   ‚úÖ Keycloak est√° listo (healthy + ready endpoint)"
                KEYCLOAK_READY=1
                break
              fi
              sleep 2
            done
            
            # Si el endpoint no responde pero est√° healthy, intentar configurar credenciales directamente
            # (a veces el endpoint tarda m√°s pero Keycloak ya acepta conexiones)
            if [ $$KEYCLOAK_READY -eq 0 ]; then
              if docker exec keycloak /opt/keycloak/bin/kcadm.sh config credentials \
                --server http://localhost:8080 \
                --realm master \
                --user "$${KEYCLOAK_ADMIN_USER}" \
                --password "$${KEYCLOAK_ADMIN_PASSWORD}" > /dev/null 2>&1; then
                echo "   ‚úÖ Keycloak est√° listo (healthy, endpoint puede tardar pero acepta conexiones)"
                KEYCLOAK_READY=1
                break
              fi
            fi
            
            if [ $$KEYCLOAK_READY -eq 1 ]; then
              break
            fi
          fi
          
          sleep 5
          ELAPSED=$$((ELAPSED + 5))
          if [ $$((ELAPSED % 20)) -eq 0 ]; then
            echo "   Esperando... ($${ELAPSED}s/$${MAX_WAIT}s)"
          fi
        done
        
        if [ $$KEYCLOAK_READY -eq 0 ]; then
          echo "   ‚ö†Ô∏è Keycloak no est√° completamente listo despu√©s de $${MAX_WAIT}s"
          echo "   ‚ö†Ô∏è Intentando continuar de todas formas..."
        fi
        echo ""
        
        # Configurar credenciales de administrador
        echo "üîê Configurando credenciales de administrador..."
        docker exec keycloak /opt/keycloak/bin/kcadm.sh config credentials \
          --server http://localhost:8080 \
          --realm master \
          --user "$${KEYCLOAK_ADMIN_USER}" \
          --password "$${KEYCLOAK_ADMIN_PASSWORD}" > /dev/null 2>&1 || {
          echo "   ‚ö†Ô∏è No se pudieron configurar credenciales"
          exit 1
        }
        echo "   ‚úÖ Credenciales configuradas"
        echo ""
        
        # Funci√≥n auxiliar para crear O ACTUALIZAR cliente
        create_or_update_client() {
          local CLIENT_ID=$$1
          local CLIENT_NAME=$$2
          local REDIRECT_URI=$$3
          local WEB_ORIGIN=$$4
          local CLIENT_SECRET=$$5
          
          echo "   Processing client '$$CLIENT_ID'..."
          
          # Verificar si existe
          if docker exec keycloak /opt/keycloak/bin/kcadm.sh get clients \
            -r "$${KEYCLOAK_REALM}" \
            -q clientId="$$CLIENT_ID" 2>/dev/null | grep -q "$$CLIENT_ID"; then
            echo "      Client exists. Updating configuration and secret..."
            # Obtener ID interno (UUID)
            local UUID=$$(docker exec keycloak /opt/keycloak/bin/kcadm.sh get clients -r "$${KEYCLOAK_REALM}" -q clientId="$$CLIENT_ID" --fields id --format csv --noquotes)
             
            if [ -n "$$UUID" ]; then
                 docker exec keycloak /opt/keycloak/bin/kcadm.sh update clients/$$UUID \
                    -r "$${KEYCLOAK_REALM}" \
                    -s secret="$$CLIENT_SECRET" \
                    -s "redirectUris=[\"$$REDIRECT_URI\"]" \
                    -s "webOrigins=[\"$$WEB_ORIGIN\"]" \
                    -s enabled=true \
                    > /dev/null 2>&1 && echo "      ‚úÖ Client updated successfully" || echo "      ‚ö†Ô∏è Error updating client"
            else
                echo "      ‚ö†Ô∏è Error finding UUID for update"
            fi
            return 0
          fi
          
          # Crear cliente
          echo "      Creating new client..."
          docker exec keycloak /opt/keycloak/bin/kcadm.sh create clients \
            -r "$${KEYCLOAK_REALM}" \
            -s clientId="$$CLIENT_ID" \
            -s name="$$CLIENT_NAME" \
            -s secret="$$CLIENT_SECRET" \
            -s protocol=openid-connect \
            -s publicClient=false \
            -s standardFlowEnabled=true \
            -s directAccessGrantsEnabled=false \
            -s fullScopeAllowed=false \
            -s "redirectUris=[\"$$REDIRECT_URI\"]" \
            -s "webOrigins=[\"$$WEB_ORIGIN\"]" \
            > /dev/null 2>&1 && echo "      ‚úÖ Client '$$CLIENT_ID' created" || echo "      ‚ö†Ô∏è Error creating '$$CLIENT_ID'"
        }
        
        # Crear o actualizar clientes
        create_or_update_client "grafana" "grafana" "$${GRAFANA_URL_PUBLIC}/login/generic_oauth" "$${GRAFANA_URL_PUBLIC}" "$${GRAFANA_OAUTH_CLIENT_SECRET}"
        create_or_update_client "n8n" "n8n" "$${N8N_URL_PUBLIC}/rest/oauth2-credential/callback" "$${N8N_URL_PUBLIC}" "$${N8N_OIDC_CLIENT_SECRET}"
        create_or_update_client "open-webui" "open-webui" "$${OPEN_WEBUI_URL_PUBLIC}/oauth/oidc/callback" "$${OPEN_WEBUI_URL_PUBLIC}" "$${OPEN_WEBUI_OAUTH_CLIENT_SECRET}"
        create_or_update_client "jenkins" "jenkins" "$${JENKINS_URL_PUBLIC}/securityRealm/finishLogin" "$${JENKINS_URL_PUBLIC}" "$${JENKINS_OIDC_CLIENT_SECRET}"
        
        echo ""
        echo "‚úÖ Clientes OIDC procesados"
    depends_on:
      keycloak:
        condition: service_healthy
    restart: "no"  # Solo se ejecuta una vez
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # ModSecurity - Firewall de aplicaciones web
  modsecurity:
    image: owasp/modsecurity-crs:nginx
    container_name: modsecurity
    profiles: ["security"]
    volumes:
      - ./modsecurity/modsecurity.conf:/etc/nginx/modsecurity/modsecurity.conf:ro
      - ./modsecurity/rules:/etc/nginx/modsecurity/rules:ro
      - modsecurity_data:/var/log/modsecurity
    networks:
      - security-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

  # =============================================================================
  # SERVICIOS DE AUTOMATIZACI√ìN Y CI/CD
  # =============================================================================
  # Servicios para automatizar tareas y desarrollo

  # Watchtower - Actualizaciones autom√°ticas de contenedores
  watchtower:
    image: containrrr/watchtower:latest
    container_name: watchtower
    profiles: ["automation"]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - WATCHTOWER_CLEANUP=${WATCHTOWER_CLEANUP:-true}
      - WATCHTOWER_SCHEDULE=${WATCHTOWER_SCHEDULE:-0 0 2 * * *}  # Actualizar a las 2 AM
      - WATCHTOWER_NOTIFICATIONS=${WATCHTOWER_NOTIFICATIONS:-email}
      - WATCHTOWER_EMAIL_FROM=${WATCHTOWER_EMAIL_FROM:-watchtower@yourdomain.com}
      - WATCHTOWER_EMAIL_TO=${WATCHTOWER_EMAIL_TO:-admin@yourdomain.com}
      - WATCHTOWER_EMAIL_SERVER=${WATCHTOWER_EMAIL_SERVER:-smtp.gmail.com}
      - WATCHTOWER_EMAIL_SERVER_PORT=${WATCHTOWER_EMAIL_SERVER_PORT:-587}
      - WATCHTOWER_EMAIL_SERVER_USER=${WATCHTOWER_EMAIL_SERVER_USER:-your-email@gmail.com}
      - WATCHTOWER_EMAIL_SERVER_PASSWORD=${WATCHTOWER_EMAIL_SERVER_PASSWORD:-your-app-password}
    networks:
      - monitoring-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Jenkins - CI/CD Pipeline
  jenkins:
    image: jenkins/jenkins:lts
    container_name: jenkins
    profiles: ["ci-cd"]
    ports:
      - "${PORT_JENKINS_HOST:-8081}:8082"
      - "${PORT_JENKINS_AGENT_HOST:-50000}:${PORT_JENKINS_AGENT_CONTAINER:-50000}"
    volumes:
      - jenkins_data:/var/jenkins_home
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - JENKINS_OPTS=--httpPort=8082
      # Variables para script de inicializaci√≥n OIDC
      - JENKINS_URL_PUBLIC=${JENKINS_URL_PUBLIC:-http://localhost:8081}
      - JENKINS_ADMIN_USER=${JENKINS_ADMIN_USER:-admin}
      - JENKINS_ADMIN_PASSWORD=${JENKINS_ADMIN_PASSWORD:-admin}
      - JENKINS_OIDC_CLIENT_ID=${JENKINS_OIDC_CLIENT_ID:-jenkins}
      - JENKINS_OIDC_CLIENT_SECRET=${JENKINS_OIDC_CLIENT_SECRET:-}
      - JENKINS_OIDC_SCOPES=${JENKINS_OIDC_SCOPES:-openid email profile}
      - KEYCLOAK_URL_PUBLIC=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}
      - KEYCLOAK_REALM=${KEYCLOAK_REALM:-master}
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/login"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G

  # Servicio de testing autom√°tico
  test-runner:
    image: alpine:latest
    container_name: test-runner
    profiles: ["testing"]
    volumes:
      - .:/workspace
    command: |
      sh -c "
      apk add --no-cache curl
      while true; do
        echo 'Testing services...'
        curl -f http://open-webui:8080/healthz || echo 'Open WebUI down'
        curl -f http://n8n:5678/healthz || echo 'n8n down'
        curl -f http://ollama:11434/api/tags || echo 'Ollama down'
        curl -f http://qdrant:6333/health || echo 'Qdrant down'
        echo 'Tests completed at $$(date)'
        sleep 300
      done
      "
    networks:
      - genai-network
    depends_on:
      - open-webui
      - n8n
      - ollama
      - qdrant
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Servicio de sincronizaci√≥n de datos
  sync:
    image: alpine:latest
    container_name: sync
    profiles: ["automation"]
    volumes:
      - shared_data:/data
      - backup_data:/backup
    command: |
      sh -c "
      apk add --no-cache rsync
      while true; do
        echo 'Syncing data...'
        rsync -av /data/ /backup/sync/
        echo 'Sync completed at $$(date)'
        sleep 3600
      done
      "
    networks:
      - backend-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Servicio de debugging avanzado
  debug-tools:
    image: alpine:latest
    container_name: debug-tools
    profiles: ["debug"]
    volumes:
      - .:/workspace
      - /var/run/docker.sock:/var/run/docker.sock
    working_dir: /workspace
    command: |
      sh -c "
      apk add --no-cache curl jq htop vim nano git docker-cli
      echo 'Debug tools ready. Available commands:'
      echo '- curl: HTTP requests'
      echo '- jq: JSON processing'
      echo '- htop: Process monitoring'
      echo '- vim/nano: Text editing'
      echo '- git: Version control'
      echo '- docker: Container management'
      tail -f /dev/null
      "
    networks:
      - genai-network
      - monitoring-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
