# =============================================================================
# MY SELF-HOSTED AI KIT - Docker Compose Configuration
# =============================================================================
# Este archivo define todos los servicios necesarios para ejecutar un stack
# completo de herramientas de Inteligencia Artificial auto-hospedadas.
#
# SERVICIOS INCLUIDOS:
# - Ollama: Servidor de modelos de lenguaje local (LLMs)
# - Open WebUI: Interfaz web moderna para chat con IA
# - n8n: Plataforma de automatización de flujos de trabajo
# - PostgreSQL: Base de datos para n8n
# - Qdrant: Base de datos vectorial para embeddings
# - pgvector: Extensión de PostgreSQL para vectores
# =============================================================================

# =============================================================================
# CONFIGURACIÓN COMÚN Y VARIABLES DE ENTORNO
# =============================================================================
# Configuración compartida entre servicios para consistencia
x-common-env: &common-env
  # Configuración de zona horaria
  TZ: ${TZ:-UTC}
  # Configuración de usuario/grupo (para permisos de archivos)
  PUID: ${PUID:-1000}
  PGID: ${PGID:-1000}

# Configuración de desarrollo vs producción
x-dev-config: &dev-config
  environment:
    - DEBUG=${DEBUG:-true}
    - LOG_LEVEL=${LOG_LEVEL:-debug}
  restart: "no"

x-prod-config: &prod-config
  environment:
    - DEBUG=${DEBUG:-false}
    - LOG_LEVEL=${LOG_LEVEL:-info}
  restart: unless-stopped

# =============================================================================
# VOLÚMENES PERSISTENTES
# =============================================================================
# Los volúmenes almacenan datos de forma persistente, sobreviviendo a reinicios
# y eliminación de contenedores. Todos los datos importantes se guardan aquí.
volumes:
  n8n_storage:        # Datos de n8n (workflows, credenciales, configuraciones)
  postgres_storage:   # Base de datos PostgreSQL principal
  ollama_storage:     # Modelos de IA descargados (¡pueden ser muy grandes!)
  qdrant_storage:     # Base de datos vectorial Qdrant
  pgvector_data:      # Base de datos PostgreSQL con extensión vectorial
  open_webui_storage: # Datos de Open WebUI (chats, configuraciones)
  n8n_data:           # Datos de importación/exportación de n8n
  shared_data:        # Datos compartidos entre servicios
  # Nuevos volúmenes para mejoras
  prometheus_data:    # Datos de métricas de Prometheus
  grafana_data:       # Datos de Grafana
  alertmanager_data:  # Datos de AlertManager
  backup_data:        # Datos de respaldos automáticos
  # Volúmenes para nuevas mejoras
  redis_data:         # Cache Redis
  jenkins_data:       # Datos de Jenkins CI/CD
  haproxy_data:       # Configuración de HAProxy
  keycloak_data:      # Datos de Keycloak
  modsecurity_data:   # Reglas de ModSecurity
  cadvisor_data:      # Datos de cAdvisor
  node_exporter_data: # Datos de Node Exporter
  postgres_exporter_data: # Datos de PostgreSQL Exporter
  # Volúmenes para mejoras de persistencia
  config_data:        # Configuraciones persistentes (Prometheus, Grafana, AlertManager, HAProxy, ModSecurity)
  ssl_certs_data:     # Certificados SSL/TLS generados
  logs_data:          # Logs consolidados de todos los servicios
  grafana_provisioning_data: # Dashboards y datasources provisionados de Grafana
  prometheus_rules_data: # Reglas de alertas personalizadas de Prometheus

# =============================================================================
# REDES
# =============================================================================
# Define redes personalizadas para separar frontend y backend
networks:
  genai-network:
    driver: bridge
    name: genai-network
  frontend-network:
    driver: bridge
    name: frontend-network
  backend-network:
    driver: bridge
    name: backend-network
    internal: true  # Solo comunicación interna
  monitoring-network:
    driver: bridge
    name: monitoring-network
  security-network:
    driver: bridge
    name: security-network
    internal: true

# =============================================================================
# PLANTILLAS DE SERVICIOS (YAML Anchors)
# =============================================================================
# Estas plantillas definen configuraciones comunes que se reutilizan en
# múltiples servicios para evitar duplicación de código.

# Plantilla para servicios n8n (n8n es una plataforma de automatización)
x-n8n: &service-n8n
  #image: n8nio/n8n:latest
  # NOTA: Usar versión específica en lugar de 'latest' para evitar actualizaciones inesperadas
  # Actualizar manualmente después de hacer backup y probar workflows
  # Actualización gradual completada: 1.101.2 -> 1.110.1 -> 1.122.5
  image: docker.n8n.io/n8nio/n8n:1.122.5  # Versión más reciente (actualizado el 2025-12-07)
  networks: ['genai-network']     # Conecta a nuestra red personalizada
  environment:
    - DB_TYPE=${N8N_DB_TYPE:-postgresdb}          # Tipo de base de datos (PostgreSQL)
    - DB_POSTGRESDB_HOST=${N8N_DB_HOST:-postgres} # Host de la base de datos
    - DB_POSTGRESDB_USER=${POSTGRES_USER}     # Usuario de BD (desde .env)
    - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD} # Contraseña de BD (desde .env)
    - N8N_DIAGNOSTICS_ENABLED=${N8N_DIAGNOSTICS_ENABLED:-false}           # Desactiva telemetría
    - N8N_PERSONALIZATION_ENABLED=${N8N_PERSONALIZATION_ENABLED:-false}       # Desactiva personalización
    - N8N_ENCRYPTION_KEY                      # Clave para encriptar datos
    - N8N_USER_MANAGEMENT_JWT_SECRET          # Clave para tokens JWT
    - OLLAMA_HOST=${OLLAMA_HOST_INTERNAL:-ollama}:${OLLAMA_PORT_INTERNAL:-11434}                # Conecta con Ollama
  env_file:
    - .env                                    # Carga variables desde archivo .env
  # Configuración de logging mejorada
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"
  # Límites de recursos para evitar consumo excesivo
  deploy:
    resources:
      limits:
        cpus: '4.0'
        memory: 4G
      reservations:
        cpus: '1.0'
        memory: 1G

# Plantilla para servicios Ollama (servidor de modelos de IA)
x-ollama: &service-ollama
  image: ollama/ollama:latest     # Imagen oficial de Ollama
  container_name: ollama
  networks: ['genai-network']
  restart: unless-stopped         # Reinicia automáticamente si falla
  ports:
    - "${PORT_OLLAMA_HOST:-11434}:${PORT_OLLAMA_CONTAINER:-11434}"
  volumes:
    - ollama_storage:/root/.ollama # Almacena modelos descargados
  healthcheck:                    # Verifica que el servicio esté funcionando
    test: ["CMD-SHELL", "pgrep -f ollama || exit 1"]
    interval: 10s                 # Verifica cada 10 segundos
    timeout: 5s                   # Timeout de 5 segundos
    retries: 5                    # Reintenta 5 veces antes de marcar como unhealthy
    start_period: 10s             # Espera 10 segundos antes de empezar healthchecks
  # Configuración de logging mejorada
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"
  # Límites de recursos (Ollama puede consumir mucha RAM)
  deploy:
    resources:
      limits:
        cpus: '6.0'
        memory: 32G
      reservations:
        cpus: '2.0'
        memory: 8G

# Plantilla para inicialización de modelos de Ollama
# Este servicio descarga automáticamente los modelos de IA al iniciar
x-init-ollama: &init-ollama
  image: ollama/ollama:latest
  networks: ['genai-network']
  container_name: ollama-pull-llama
  volumes:
    - ollama_storage:/root/.ollama # Comparte el mismo volumen que ollama
  entrypoint: /bin/sh              # Usa shell para ejecutar comandos
  environment:
    - OLLAMA_HOST=${OLLAMA_HOST_INTERNAL:-ollama}:${OLLAMA_PORT_INTERNAL:-11434}     # Conecta con el servicio ollama
  command:
    - "-c"
    - |
      set -e                       # Termina si cualquier comando falla
      echo "Descargando llama3.2..."
      ollama pull llama3.2 || { echo "❌ Falló llama3.2"; exit 1; }

      echo "Descargando llama3.3..."
      ollama pull llama3.3 || { echo "❌ Falló llama3.3"; exit 1; }

      echo "Descargando all-minilm..."
      ollama pull all-minilm || { echo "❌ Falló all-minilm"; exit 1; }

      #echo "Descargando all-minilm:33m..."
      #ollama pull all-minilm:33m || { echo "❌ Falló all-minilm:33m"; exit 1; }

      echo "Descargando deepseek-r1:14b..."
      ollama pull deepseek-r1:14b || { echo "❌ Falló deepseek"; exit 1; }

      echo "Descargando nomic-embed-text..."
      ollama pull nomic-embed-text || { echo "❌ Falló nomic-embed-text"; exit 1; }

      echo "✅ Todos los modelos fueron descargados correctamente"
  # Configuración de logging
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"

# =============================================================================
# SERVICIOS PRINCIPALES
# =============================================================================

services:
  # Inicializador de base de datos para Keycloak
  postgres-init:
    image: postgres:16-alpine
    container_name: postgres-init
    profiles: ["security"]
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - postgres_storage:/var/lib/postgresql/data
      - ./scripts/init-keycloak-db.sql:/docker-entrypoint-initdb.d/init-keycloak-db.sql
    networks:
      - genai-network
    command: postgres -c 'max_connections=${POSTGRES_MAX_CONNECTIONS:-200}'
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -h localhost -U ${POSTGRES_USER} -d ${POSTGRES_DB}']
      interval: 5s
      timeout: 5s
      retries: 10
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G

  postgres:
    image: postgres:16-alpine      # PostgreSQL 16 con Alpine Linux (más ligero)
    hostname: ${POSTGRES_HOSTNAME:-postgres}
    container_name: postgres
    networks: ['genai-network']
    restart: unless-stopped
    environment:
      - POSTGRES_USER              # Usuario de BD (desde .env)
      - POSTGRES_PASSWORD          # Contraseña de BD (desde .env)
      - POSTGRES_DB                # Nombre de BD (desde .env)
    volumes:
      - postgres_storage:/var/lib/postgresql/data  # Datos persistentes
    healthcheck:                   # Verifica que PostgreSQL esté listo
      test: ['CMD-SHELL', 'pg_isready -h localhost -U ${POSTGRES_USER} -d ${POSTGRES_DB}']
      interval: 5s
      timeout: 5s
      retries: 10
    # Configuración de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Límites de recursos
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G

  # Base de datos PostgreSQL con extensión vectorial (para embeddings)
  pgvector:
    image: ankane/pgvector         # PostgreSQL con extensión pgvector
    container_name: pgvector
    networks: ['genai-network']
    environment:
      POSTGRES_USER: ${PGVECTOR_USER:-user}
      POSTGRES_PASSWORD: ${PGVECTOR_PASSWORD:-password}
      POSTGRES_DB: ${PGVECTOR_DB:-pgvector_db}
    ports:
      - "${PORT_PGVECTOR_HOST:-5433}:${PORT_PGVECTOR_CONTAINER:-5432}"
    restart: unless-stopped
    volumes:
      - pgvector_data:/var/lib/postgresql/data
    # Configuración de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Límites de recursos
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G

  # Interfaz web moderna para chat con IA
  open-webui:
    image: ghcr.io/open-webui/open-webui:0.6.41 # Versión más reciente - probando mejoras OIDC
    container_name: open-webui
    profiles: ["chat-ai"]          # Perfil de chat con IA (requiere --profile security para Keycloak)
    ports:
      - "${PORT_OPEN_WEBUI_HOST:-3000}:${PORT_OPEN_WEBUI_CONTAINER:-8080}"
    environment:
      # OLLAMA_BASE_URL: URL interna para conectar con Ollama desde el contenedor
      # IMPORTANTE: Si OLLAMA_URL_INTERNAL está vacía en .env, debe tener un valor o no estar definida
      # Si está definida pero vacía, Docker Compose la pasa como cadena vacía y ${VAR:-default} no funciona
      - OLLAMA_BASE_URL=${OLLAMA_URL_INTERNAL:-http://ollama:11434}
      - USER_AGENT=${OPEN_WEBUI_USER_AGENT:-OpenWebUI/0.6.13}
      - CORS_ALLOW_ORIGIN=${OPEN_WEBUI_URL_PUBLIC:-http://localhost:3000}
      # Configuración de usuarios y acceso
      - ENABLE_SIGNUP=${OPEN_WEBUI_ENABLE_SIGNUP:-true}  # Permitir registro de usuarios
      - ENABLE_LOGIN_FORM=${OPEN_WEBUI_ENABLE_LOGIN_FORM:-true}  # Permitir login con formulario
      # Configuración OIDC/OAuth con Keycloak
      - ENABLE_OAUTH_SSO=${OPEN_WEBUI_ENABLE_OAUTH_SSO:-true}
      - ENABLE_OAUTH_SIGNUP=${OPEN_WEBUI_ENABLE_OAUTH_SIGNUP:-true}  # Permitir registro automático de usuarios OAuth
      - OAUTH_CLIENT_ID=${OPEN_WEBUI_OAUTH_CLIENT_ID:-open-webui}
      - OAUTH_CLIENT_SECRET=${OPEN_WEBUI_OAUTH_CLIENT_SECRET}
      - OAUTH_PROVIDER_NAME=${OPEN_WEBUI_OAUTH_PROVIDER_NAME:-Keycloak}
      # Configuración OIDC - LIMITACIÓN CONOCIDA DE OPEN WEBUI
      # Problema: Open WebUI usa URLs del discovery document (localhost:8080) 
      # en lugar de las URLs explícitas (keycloak:8080), causando error 405
      # Esto es una limitación de Open WebUI que no respeta URLs explícitas
      # cuando hay un discovery document configurado
      - OPENID_ENABLED=${OPEN_WEBUI_OAUTH_ENABLED:-true}  # OpenID usa variables OAUTH_ (consolidado según documentación)
      - OPENID_CLIENT_ID=${OPEN_WEBUI_OAUTH_CLIENT_ID:-open-webui}  # OpenID usa variables OAUTH_ (consolidado según documentación)
      - OPENID_CLIENT_SECRET=${OPEN_WEBUI_OAUTH_CLIENT_SECRET}  # OpenID usa variables OAUTH_ (consolidado según documentación)
      # OPENID_PROVIDER_URL necesario para que aparezca el botón
      - OPENID_PROVIDER_URL=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/.well-known/openid-configuration
      - OPENID_REDIRECT_URI=${OPEN_WEBUI_URL_PUBLIC:-http://localhost:3000}/oauth/oidc/callback
      # URLs explícitas configuradas pero Open WebUI las ignora cuando hay discovery document
      - OPENID_AUTHORIZATION_ENDPOINT=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/auth
      - OPENID_TOKEN_ENDPOINT=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/token
      - OPENID_USERINFO_ENDPOINT=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/userinfo
      - OPENID_ISSUER=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}
      - OPENID_SCOPES=${OPEN_WEBUI_OAUTH_SCOPES:-openid profile email}  # OpenID usa variables OAUTH_ (consolidado según documentación)
      - OPENID_SIGN_OUT_REDIRECT_URL=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/logout
    volumes:
      - open_webui_storage:/app/backend/data   # Datos persistentes
      #- /mnt/e/docker/app/open-webui/backend/data:/app/backend/data  # Montaje local (comentado)
    networks:
      - genai-network
    depends_on:
      keycloak:
        condition: service_healthy     # Espera a que Keycloak esté listo (requiere --profile security)
      # NOTA: Ollama está en perfiles (ollama-gpu, ollama-cpu, etc.) - no puede depender explícitamente
      # Open WebUI puede iniciar sin Ollama, pero no funcionará completamente hasta que esté listo
    healthcheck:                   # Verifica que Open WebUI esté funcionando
      test: ["CMD", "curl", "-f", "http://localhost:8080/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5
    # Configuración de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Límites de recursos
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G
#    depends_on:
#      ollama-gpu:
#        condition: service_healthy

  # Servicio de importación de datos para n8n (se ejecuta una vez al inicio)
  n8n-import:
    <<: *service-n8n               # Usa la plantilla n8n
    hostname: n8n-import
    container_name: n8n-import
    networks: ['genai-network']
    entrypoint: /bin/sh            # Usa shell para ejecutar comandos de importación
    command:
      - "-c"
      - "n8n import:credentials --separate --input=/data/credentials && n8n import:workflow --separate --input=/data/workflows"
    volumes:
      - n8n_data:/data             # Datos de importación/exportación
    depends_on:
      postgres:
        condition: service_healthy # Espera a que PostgreSQL esté listo
    healthcheck:                   # Verifica que n8n-import esté funcionando
      test: ["CMD", "curl", "-f", "http://n8n:5678/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Servicio principal de n8n (plataforma de automatización)
  n8n:
    <<: *service-n8n               # Usa la plantilla n8n
    hostname: n8n
    container_name: n8n
    profiles: ["automation"]        # Perfil de automatización (requiere --profile security para Keycloak)
    restart: unless-stopped
    ports:
      - "${PORT_N8N_HOST:-5678}:${PORT_N8N_CONTAINER:-5678}"
    environment:
      - N8N_RUNNERS_ENABLED=${N8N_RUNNERS_ENABLED:-true}
      - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=${N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS:-true}
      # Configuración OIDC/OAuth con Keycloak
      - N8N_AUTH_TYPE=${N8N_AUTH_TYPE:-oidc}
      - N8N_OIDC_ISSUER=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}
      - N8N_OIDC_CLIENT_ID=${N8N_OIDC_CLIENT_ID:-n8n}
      - N8N_OIDC_CLIENT_SECRET=${N8N_OIDC_CLIENT_SECRET:-change_me_n8n_client_secret}
      # URLs explícitas - authorization usa localhost (navegador), token/userinfo usan keycloak (interno)
      - N8N_OIDC_AUTHORIZATION_URL=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/auth
      - N8N_OIDC_TOKEN_URL=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/token
      - N8N_OIDC_USER_INFO_URL=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/userinfo
      - N8N_OIDC_REDIRECT_URI=${N8N_URL_PUBLIC:-http://localhost:5678}/rest/oauth2-credential/callback
      - N8N_OIDC_SCOPES=${N8N_OIDC_SCOPES:-openid profile email}
      - N8N_OIDC_DISPLAY_NAME=${N8N_OIDC_DISPLAY_NAME:-Keycloak}
    volumes:
      - n8n_storage:/home/node/.n8n    # Datos persistentes de n8n
      - n8n_data:/data                 # Datos de importación/exportación
      - shared_data:/data/shared       # Datos compartidos
    depends_on:
      postgres:
        condition: service_healthy     # Espera a que PostgreSQL esté listo
      n8n-import:
        condition: service_completed_successfully  # Espera a que termine la importación
      keycloak:
        condition: service_healthy     # Espera a que Keycloak esté listo (requiere --profile security)
    healthcheck:                       # Verifica que n8n esté funcionando
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:5678/healthz || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Base de datos vectorial Qdrant (para embeddings y búsqueda semántica)
  qdrant:
    image: qdrant/qdrant
    hostname: qdrant
    container_name: qdrant
    networks: ['genai-network']
    restart: unless-stopped
    ports:
      - "${PORT_QDRANT_HOST:-6333}:${PORT_QDRANT_CONTAINER:-6333}"
    volumes:
      - qdrant_storage:/qdrant/storage  # Datos persistentes
    healthcheck:                   # Verifica que Qdrant esté funcionando
      test: ["CMD-SHELL", "for pid in /proc/*/comm; do [ -f \"$$pid\" ] && grep -q qdrant \"$$pid\" 2>/dev/null && exit 0; done; exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    # Configuración de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Límites de recursos
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G

  # =============================================================================
  # SERVICIOS DE OLLAMA (DIFERENTES PERFILES)
  # =============================================================================
  # Estos servicios usan perfiles para activar solo uno según el hardware disponible

  # Perfil CPU: Ollama usando solo CPU (más lento pero funciona en cualquier máquina)
  ollama-cpu:
    profiles: ["cpu"]              # Solo se activa con --profile cpu
    <<: *service-ollama            # Usa la plantilla ollama

  # Perfil GPU NVIDIA: Ollama con aceleración GPU NVIDIA
  ollama-gpu:
    profiles: ["gpu-nvidia"]       # Solo se activa con --profile gpu-nvidia
    <<: *service-ollama            # Usa la plantilla ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia        # Usa driver NVIDIA
              count: 1              # Usa 1 GPU
              capabilities: [gpu]   # Habilita capacidades GPU

  # Perfil GPU AMD: Ollama con aceleración GPU AMD
  ollama-gpu-amd:
    profiles: ["gpu-amd"]          # Solo se activa con --profile gpu-amd
    <<: *service-ollama
    image: ollama/ollama:rocm      # Imagen con soporte ROCm (AMD)
    devices:
      - "/dev/kfd"                 # Dispositivo AMD GPU
      - "/dev/dri"                 # Dispositivo de renderizado



  # =============================================================================
  # SERVICIOS DE INICIALIZACIÓN DE MODELOS (DIFERENTES PERFILES)
  # =============================================================================
  # Estos servicios descargan los modelos de IA según el perfil activado

  # Descarga de modelos para CPU
  # ollama-pull-llama-cpu:
  #   profiles: ["cpu"]
  #   <<: *init-ollama               # Usa la plantilla de inicialización
  #   depends_on:
  #     - ollama-cpu                 # Espera a que ollama-cpu esté listo

  # Descarga de modelos para GPU NVIDIA
  # ollama-pull-llama-gpu:
  #   profiles: ["gpu-nvidia"]
  #   <<: *init-ollama               # Usa la plantilla de inicialización
  #   depends_on:
  #     - ollama-gpu                 # Espera a que ollama-gpu esté listo

  # Descarga de modelos para GPU AMD
  # ollama-pull-llama-gpu-amd:
  #   profiles: [gpu-amd]
  #   <<: *init-ollama               # Usa la plantilla de inicialización
  #   image: ollama/ollama:rocm      # Imagen con soporte ROCm
  #   depends_on:
  #    - ollama-gpu-amd              # Espera a que ollama-gpu-amd esté listo

  # =============================================================================
  # SERVICIOS DE MONITOREO Y MANTENIMIENTO (OPCIONALES)
  # =============================================================================
  # Estos servicios ayudan a monitorear y mantener el stack

  # Prometheus - Recolector de métricas
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    profiles: ["monitoring"]
    ports:
      - "${PORT_PROMETHEUS_HOST:-9090}:${PORT_PROMETHEUS_CONTAINER:-9090}"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus_rules_data:/etc/prometheus/rules/custom:ro  # Reglas personalizadas persistentes
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - monitoring-network
      - genai-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

  # Grafana - Dashboards y visualización
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    profiles: ["monitoring"]
    ports:
      - "${PORT_GRAFANA_HOST:-3001}:${PORT_GRAFANA_CONTAINER:-3000}"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./monitoring/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/config/grafana.ini:/etc/grafana/grafana.ini:ro
      # Volumen para dashboards personalizados creados por usuarios
      - grafana_provisioning_data:/var/lib/grafana/dashboards/custom:ro
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=${GRAFANA_USERS_ALLOW_SIGN_UP:-false}
      - GF_AUTH_GENERIC_OAUTH_ENABLED=${GRAFANA_AUTH_GENERIC_OAUTH_ENABLED:-true}
      - GF_AUTH_GENERIC_OAUTH_NAME=${GRAFANA_OAUTH_NAME:-Keycloak}
      - GF_AUTH_GENERIC_OAUTH_CLIENT_ID=${GRAFANA_OAUTH_CLIENT_ID:-grafana}
      - GF_AUTH_GENERIC_OAUTH_CLIENT_SECRET=${GRAFANA_OAUTH_CLIENT_SECRET}
      - GF_AUTH_GENERIC_OAUTH_SCOPES=${GRAFANA_OAUTH_SCOPES:-openid profile email}
      # AUTH_URL debe usar localhost porque el navegador del usuario necesita acceder
      - GF_AUTH_GENERIC_OAUTH_AUTH_URL=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/auth
      # TOKEN_URL y API_URL pueden usar keycloak:8080 porque Grafana las llama desde dentro del contenedor
      - GF_AUTH_GENERIC_OAUTH_TOKEN_URL=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/token
      - GF_AUTH_GENERIC_OAUTH_API_URL=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/userinfo
      - GF_AUTH_GENERIC_OAUTH_SKIP_ORG_ROLE_SYNC=${GRAFANA_SKIP_ORG_ROLE_SYNC:-true}  # Necesario: Keycloak devuelve realm roles del usuario admin que Grafana intenta sincronizar
      # SIGNOUT_REDIRECT_URL debe usar localhost porque el navegador del usuario necesita acceder
      - GF_AUTH_SIGNOUT_REDIRECT_URL=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/logout
      - GF_SERVER_ROOT_URL=${GRAFANA_URL_PUBLIC:-http://localhost:3001}
      - GF_USERS_AUTO_LOGIN=${GRAFANA_USERS_AUTO_LOGIN:-false}
      - GF_AUTH_DISABLE_LOGIN_FORM=${GRAFANA_AUTH_DISABLE_LOGIN_FORM:-true}  # Solo Keycloak OAuth (más seguro)
    networks:
      - monitoring-network
      - genai-network
    depends_on:
      prometheus:
        condition: service_healthy
      keycloak:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

  # AlertManager - Gestión de alertas
  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    profiles: ["monitoring"]
    ports:
      - "${PORT_ALERTMANAGER_HOST:-9093}:${PORT_ALERTMANAGER_CONTAINER:-9093}"
    volumes:
      - ./monitoring/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    networks:
      - monitoring-network
      - genai-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M

  # Servicio de backup automático
  backup:
    image: alpine:latest
    container_name: backup
    profiles: ["monitoring"]       # Solo se activa con --profile monitoring
    volumes:
      - n8n_storage:/data/n8n:ro
      - postgres_storage:/data/postgres:ro
      - backup_data:/backups
    command: |
      sh -c "
      apk add --no-cache tar
      while true; do
        tar -czf /backups/backup-$$(date +%Y%m%d-%H%M%S).tar.gz -C /data .
        sleep 86400
      done
      "
    # Configuración de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Límites de recursos
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M

  # Servicio de herramientas de desarrollo
  dev-tools:
    image: alpine:latest
    container_name: dev-tools
    profiles: ["dev"]              # Solo se activa con --profile dev
    volumes:
      - .:/workspace
    working_dir: /workspace
    command: sh -c "apk add --no-cache curl jq && tail -f /dev/null"
    # Configuración de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Límites de recursos
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Node Exporter - Métricas del host
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    profiles: ["monitoring"]
    ports:
      - "${PORT_NODE_EXPORTER_HOST:-9100}:${PORT_NODE_EXPORTER_CONTAINER:-9100}"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - monitoring-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9100/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # cAdvisor - Métricas de contenedores
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    profiles: ["monitoring"]
    ports:
      - "${PORT_CADVISOR_HOST:-8082}:${PORT_CADVISOR_CONTAINER:-8080}"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro  # Necesario para descubrir contenedores
    networks:
      - monitoring-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M

  # PostgreSQL Exporter - Métricas de PostgreSQL
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: postgres-exporter
    profiles: ["monitoring"]
    environment:
      DATA_SOURCE_NAME: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?sslmode=disable"
    ports:
      - "${PORT_POSTGRES_EXPORTER_HOST:-9187}:${PORT_POSTGRES_EXPORTER_CONTAINER:-9187}"
    networks:
      - monitoring-network
      - genai-network  # Necesario para conectarse a PostgreSQL
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9187/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # =============================================================================
  # SERVICIOS DE INFRAESTRUCTURA
  # =============================================================================
  # Servicios que mejoran el rendimiento y escalabilidad

  # Redis - Cache y sesiones
  redis:
    image: redis:alpine
    container_name: redis
    profiles: ["infrastructure"]
    ports:
      - "${PORT_REDIS_HOST:-6379}:${PORT_REDIS_CONTAINER:-6379}"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.25'
          memory: 512M

  # HAProxy - Load Balancer
  haproxy:
    image: haproxy:latest
    container_name: haproxy
    profiles: ["infrastructure"]
    ports:
      - "${PORT_HAPROXY_HTTP_HOST:-80}:${PORT_HAPROXY_HTTP_CONTAINER:-80}"
      - "${PORT_HAPROXY_HTTPS_HOST:-443}:${PORT_HAPROXY_HTTPS_CONTAINER:-443}"
    volumes:
      - ./haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
      - haproxy_data:/var/lib/haproxy
    networks:
      - frontend-network
      - backend-network
      - genai-network
    depends_on:
      open-webui:
        condition: service_healthy
      n8n:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "haproxy", "-c", "-f", "/usr/local/etc/haproxy/haproxy.cfg"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M



  # =============================================================================
  # SERVICIOS DE SEGURIDAD Y AUTENTICACIÓN
  # =============================================================================
  # Servicios para mejorar la seguridad del stack

  # Keycloak - Autenticación centralizada
  keycloak:
    image: quay.io/keycloak/keycloak:latest
    container_name: keycloak
    profiles: ["security"]
    environment:
      - KEYCLOAK_ADMIN=${KEYCLOAK_ADMIN_USER:-admin}
      - KEYCLOAK_ADMIN_PASSWORD=${KEYCLOAK_ADMIN_PASSWORD:-admin}
      - KC_DB=${KEYCLOAK_DB_TYPE:-postgres}
      - KC_DB_URL=jdbc:postgresql://${POSTGRES_HOST_INTERNAL:-postgres}:${POSTGRES_PORT_INTERNAL:-5432}/${KEYCLOAK_DB_NAME:-keycloak}
      - KC_DB_USERNAME=${POSTGRES_USER}
      - KC_DB_PASSWORD=${POSTGRES_PASSWORD}
      - KC_HOSTNAME=${HOSTNAME_PUBLIC:-localhost}
      - KC_HOSTNAME_PORT=${PORT_KEYCLOAK_HOST:-8080}
      - KC_HOSTNAME_STRICT=${KEYCLOAK_HOSTNAME_STRICT:-false}
      - KC_HTTP_ENABLED=${KEYCLOAK_HTTP_ENABLED:-true}
      - KC_HEALTH_ENABLED=${KEYCLOAK_HEALTH_ENABLED:-true}
      # Configuración para cookies en contexto HTTP (no seguro)
      - KC_HTTP_RELATIVE_PATH=${KEYCLOAK_HTTP_RELATIVE_PATH:-/}
      - KC_PROXY=${KEYCLOAK_PROXY:-edge}
      - KC_PROXY_ADDRESS_FORWARDING=${KEYCLOAK_PROXY_ADDRESS_FORWARDING:-true}
    ports:
      - "${PORT_KEYCLOAK_HOST:-8080}:${PORT_KEYCLOAK_CONTAINER:-8080}"
    volumes:
      - keycloak_data:/opt/keycloak/data
    networks:
      - security-network
      - backend-network
      - genai-network
    depends_on:
      postgres:
        condition: service_healthy
    command: start-dev --http-enabled=true --hostname-strict=false
    healthcheck:
      # Keycloak no tiene curl ni wget, usamos redirección TCP nativa con /bin/sh
      # Verificamos que /realms/master responda con HTTP 200 (endpoint estándar de Keycloak)
      test: ["CMD-SHELL", "exec 3<>/dev/tcp/localhost/8080 && echo -e 'GET /realms/master HTTP/1.1\\r\\nHost: localhost\\r\\nConnection: close\\r\\n\\r\\n' >&3 && head -1 <&3 | grep -q 'HTTP/1.1 200' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # ModSecurity - Firewall de aplicaciones web
  modsecurity:
    image: owasp/modsecurity-crs:nginx
    container_name: modsecurity
    profiles: ["security"]
    volumes:
      - ./modsecurity/modsecurity.conf:/etc/nginx/modsecurity/modsecurity.conf:ro
      - ./modsecurity/rules:/etc/nginx/modsecurity/rules:ro
      - modsecurity_data:/var/log/modsecurity
    networks:
      - security-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

  # =============================================================================
  # SERVICIOS DE AUTOMATIZACIÓN Y CI/CD
  # =============================================================================
  # Servicios para automatizar tareas y desarrollo

  # Watchtower - Actualizaciones automáticas de contenedores
  watchtower:
    image: containrrr/watchtower:latest
    container_name: watchtower
    profiles: ["automation"]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - WATCHTOWER_CLEANUP=${WATCHTOWER_CLEANUP:-true}
      - WATCHTOWER_SCHEDULE=${WATCHTOWER_SCHEDULE:-0 0 2 * * *}  # Actualizar a las 2 AM
      - WATCHTOWER_NOTIFICATIONS=${WATCHTOWER_NOTIFICATIONS:-email}
      - WATCHTOWER_EMAIL_FROM=${WATCHTOWER_EMAIL_FROM:-watchtower@yourdomain.com}
      - WATCHTOWER_EMAIL_TO=${WATCHTOWER_EMAIL_TO:-admin@yourdomain.com}
      - WATCHTOWER_EMAIL_SERVER=${WATCHTOWER_EMAIL_SERVER:-smtp.gmail.com}
      - WATCHTOWER_EMAIL_SERVER_PORT=${WATCHTOWER_EMAIL_SERVER_PORT:-587}
      - WATCHTOWER_EMAIL_SERVER_USER=${WATCHTOWER_EMAIL_SERVER_USER:-your-email@gmail.com}
      - WATCHTOWER_EMAIL_SERVER_PASSWORD=${WATCHTOWER_EMAIL_SERVER_PASSWORD:-your-app-password}
    networks:
      - monitoring-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Jenkins - CI/CD Pipeline
  jenkins:
    image: jenkins/jenkins:lts
    container_name: jenkins
    profiles: ["ci-cd"]
    ports:
      - "${PORT_JENKINS_HOST:-8081}:8082"
      - "${PORT_JENKINS_AGENT_HOST:-50000}:${PORT_JENKINS_AGENT_CONTAINER:-50000}"
    volumes:
      - jenkins_data:/var/jenkins_home
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - JENKINS_OPTS=--httpPort=8082
      # Variables para script de inicialización OIDC
      - JENKINS_URL_PUBLIC=${JENKINS_URL_PUBLIC:-http://localhost:8081}
      - JENKINS_ADMIN_USER=${JENKINS_ADMIN_USER:-admin}
      - JENKINS_ADMIN_PASSWORD=${JENKINS_ADMIN_PASSWORD:-admin}
      - JENKINS_OIDC_CLIENT_ID=${JENKINS_OIDC_CLIENT_ID:-jenkins}
      - JENKINS_OIDC_CLIENT_SECRET=${JENKINS_OIDC_CLIENT_SECRET:-}
      - JENKINS_OIDC_SCOPES=${JENKINS_OIDC_SCOPES:-openid email profile}
      - KEYCLOAK_URL_PUBLIC=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}
      - KEYCLOAK_REALM=${KEYCLOAK_REALM:-master}
    networks:
      - backend-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/login"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G

  # Servicio de testing automático
  test-runner:
    image: alpine:latest
    container_name: test-runner
    profiles: ["testing"]
    volumes:
      - .:/workspace
    command: |
      sh -c "
      apk add --no-cache curl
      while true; do
        echo 'Testing services...'
        curl -f http://open-webui:8080/healthz || echo 'Open WebUI down'
        curl -f http://n8n:5678/healthz || echo 'n8n down'
        curl -f http://ollama:11434/api/tags || echo 'Ollama down'
        curl -f http://qdrant:6333/health || echo 'Qdrant down'
        echo 'Tests completed at $$(date)'
        sleep 300
      done
      "
    networks:
      - genai-network
    depends_on:
      - open-webui
      - n8n
      - ollama
      - qdrant
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Servicio de sincronización de datos
  sync:
    image: alpine:latest
    container_name: sync
    profiles: ["automation"]
    volumes:
      - shared_data:/data
      - backup_data:/backup
    command: |
      sh -c "
      apk add --no-cache rsync
      while true; do
        echo 'Syncing data...'
        rsync -av /data/ /backup/sync/
        echo 'Sync completed at $$(date)'
        sleep 3600
      done
      "
    networks:
      - backend-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Servicio de debugging avanzado
  debug-tools:
    image: alpine:latest
    container_name: debug-tools
    profiles: ["debug"]
    volumes:
      - .:/workspace
      - /var/run/docker.sock:/var/run/docker.sock
    working_dir: /workspace
    command: |
      sh -c "
      apk add --no-cache curl jq htop vim nano git docker-cli
      echo 'Debug tools ready. Available commands:'
      echo '- curl: HTTP requests'
      echo '- jq: JSON processing'
      echo '- htop: Process monitoring'
      echo '- vim/nano: Text editing'
      echo '- git: Version control'
      echo '- docker: Container management'
      tail -f /dev/null
      "
    networks:
      - genai-network
      - monitoring-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
