# =============================================================================
# MY SELF-HOSTED AI KIT - Docker Compose Configuration
# =============================================================================
# Este archivo define todos los servicios necesarios para ejecutar un stack
# completo de herramientas de Inteligencia Artificial auto-hospedadas.
#
# SERVICIOS INCLUIDOS:
# - Ollama: Servidor de modelos de lenguaje local (LLMs)
# - Open WebUI: Interfaz web moderna para chat con IA
# - n8n: Plataforma de automatizaci√≥n de flujos de trabajo
# - PostgreSQL: Base de datos para n8n
# - Qdrant: Base de datos vectorial para embeddings
# - pgvector: Extensi√≥n de PostgreSQL para vectores
# =============================================================================

# =============================================================================
# CONFIGURACI√ìN COM√öN Y VARIABLES DE ENTORNO
# =============================================================================
# Configuraci√≥n compartida entre servicios para consistencia
x-common-env:
  # Configuraci√≥n de zona horaria
  &common-env
  TZ: ${TZ:-UTC}
  # Configuraci√≥n de usuario/grupo (para permisos de archivos)
  PUID: ${PUID:-1000}
  PGID: ${PGID:-1000}

# Configuraci√≥n de desarrollo vs producci√≥n
x-dev-config: &dev-config
  environment:
    - DEBUG=${DEBUG:-true}
    - LOG_LEVEL=${LOG_LEVEL:-debug}
  restart: "no"

x-prod-config: &prod-config
  environment:
    - DEBUG=${DEBUG:-false}
    - LOG_LEVEL=${LOG_LEVEL:-info}
  restart: unless-stopped

# =============================================================================
# VOL√öMENES PERSISTENTES
# =============================================================================
# Los vol√∫menes almacenan datos de forma persistente, sobreviviendo a reinicios
# y eliminaci√≥n de contenedores. Todos los datos importantes se guardan aqu√≠.
volumes:
  n8n_storage: # Datos de n8n (workflows, credenciales, configuraciones)
  postgres_storage: # Base de datos PostgreSQL principal
  ollama_storage: # Modelos de IA descargados (¬°pueden ser muy grandes!)
  qdrant_storage: # Base de datos vectorial Qdrant
  pgvector_data: # Base de datos PostgreSQL con extensi√≥n vectorial
  open_webui_storage: # Datos de Open WebUI (chats, configuraciones)
  n8n_data: # Datos de importaci√≥n/exportaci√≥n de n8n
  shared_data:
    # Datos compartidos entre servicios
    # Nuevos vol√∫menes para mejoras

  prometheus_data: # Datos de m√©tricas de Prometheus
  grafana_data: # Datos de Grafana
  alertmanager_data: # Datos de AlertManager
  backup_data:
    # Datos de respaldos autom√°ticos
    # Vol√∫menes para nuevas mejoras

  redis_data: # Cache Redis
  jenkins_data: # Datos de Jenkins CI/CD
  haproxy_data: # Configuraci√≥n de HAProxy
  keycloak_data: # Datos de Keycloak
  modsecurity_data: # Reglas de ModSecurity
  cadvisor_data: # Datos de cAdvisor
  node_exporter_data: # Datos de Node Exporter
  postgres_exporter_data:
    # Datos de PostgreSQL Exporter
    # Vol√∫menes para mejoras de persistencia

  config_data: # Configuraciones persistentes (Prometheus, Grafana, AlertManager, HAProxy, ModSecurity)
  ssl_certs_data: # Certificados SSL/TLS generados
  logs_data: # Logs consolidados de todos los servicios
  grafana_provisioning_data: # Dashboards y datasources provisionados de Grafana
  prometheus_rules_data:
    # Reglas de alertas personalizadas de Prometheus

    # =============================================================================
    # REDES
    # =============================================================================
    # Define redes personalizadas para separar frontend y backend
networks:
  genai-network:
    driver: bridge
    name: genai-network
  frontend-network:
    driver: bridge
    name: frontend-network
  backend-network:
    driver: bridge
    name: backend-network
    internal: true # Solo comunicaci√≥n interna
  monitoring-network:
    driver: bridge
    name: monitoring-network
  security-network:
    driver: bridge
    name: security-network
    internal: true

# =============================================================================
# PLANTILLAS DE SERVICIOS (YAML Anchors)
# =============================================================================
# Estas plantillas definen configuraciones comunes que se reutilizan en
# m√∫ltiples servicios para evitar duplicaci√≥n de c√≥digo.

# Plantilla para servicios n8n (n8n es una plataforma de automatizaci√≥n)
x-n8n:
  #image: n8nio/n8n:latest
  # NOTA: Usar versi√≥n espec√≠fica en lugar de 'latest' para evitar actualizaciones inesperadas
  # Actualizar manualmente despu√©s de hacer backup y probar workflows
  # Actualizaci√≥n gradual completada: 1.101.2 -> 1.110.1 -> 1.122.5
  &service-n8n
  image: docker.n8n.io/n8nio/n8n:1.122.5 # Versi√≥n m√°s reciente (actualizado el 2025-12-07)
  networks: [ 'genai-network' ] # Conecta a nuestra red personalizada
  environment:
    - DB_TYPE=${N8N_DB_TYPE:-postgresdb} # Tipo de base de datos (PostgreSQL)
    - DB_POSTGRESDB_HOST=${N8N_DB_HOST:-postgres} # Host de la base de datos
    - DB_POSTGRESDB_USER=${POSTGRES_USER} # Usuario de BD (desde .env)
    - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD} # Contrase√±a de BD (desde .env)
    - N8N_DIAGNOSTICS_ENABLED=${N8N_DIAGNOSTICS_ENABLED:-false} # Desactiva telemetr√≠a
    - N8N_PERSONALIZATION_ENABLED=${N8N_PERSONALIZATION_ENABLED:-false} # Desactiva personalizaci√≥n
    - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY?Variable not set} # Clave para encriptar datos
    - N8N_USER_MANAGEMENT_JWT_SECRET=${N8N_USER_MANAGEMENT_JWT_SECRET?Variable not set} # Clave para tokens JWT
    - OLLAMA_HOST=${OLLAMA_HOST_INTERNAL:-ollama}:${OLLAMA_PORT_INTERNAL:-11434} # Conecta con Ollama
  env_file:
    - .env # Carga variables desde archivo .env
  # Configuraci√≥n de logging mejorada
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"
  # L√≠mites de recursos para evitar consumo excesivo
  deploy:
    resources:
      limits:
        cpus: '4.0'
        memory: 4G
      reservations:
        cpus: '1.0'
        memory: 1G

# Plantilla para servicios Ollama (servidor de modelos de IA)
x-ollama: &service-ollama
  image: ollama/ollama:latest # Imagen oficial de Ollama
  container_name: ollama
  networks: [ 'genai-network' ]
  restart: unless-stopped # Reinicia autom√°ticamente si falla
  ports:
    - "${PORT_OLLAMA_HOST:-11434}:${PORT_OLLAMA_CONTAINER:-11434}"
  volumes:
    - ollama_storage:/root/.ollama # Almacena modelos descargados
  # Variables de entorno para optimizaci√≥n de rendimiento
  environment:
    # Mantener hasta 2 modelos en memoria para acceso r√°pido (reduce tiempo de carga)
    - OLLAMA_MAX_LOADED_MODELS=${OLLAMA_MAX_LOADED_MODELS:-2}
    # Optimizar threads para CPU (8 threads para mejor balance CPU/GPU)
    - OLLAMA_NUM_THREAD=${OLLAMA_NUM_THREAD:-8}
    # Mantener modelos cargados 10 minutos para reducir tiempos de respuesta
    - OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE:-10m}
  # Configuraci√≥n de shared memory para mejor rendimiento con modelos grandes
  shm_size: ${OLLAMA_SHM_SIZE:-2g} # 2GB de memoria compartida (mejora rendimiento)
  healthcheck:
    # Verifica que el servicio est√© funcionando
    test: [ "CMD-SHELL", "pgrep -f ollama || exit 1" ]
    interval: 10s # Verifica cada 10 segundos
    timeout: 5s # Timeout de 5 segundos
    retries: 5 # Reintenta 5 veces antes de marcar como unhealthy
    start_period: 10s # Espera 10 segundos antes de empezar healthchecks
  # Configuraci√≥n de logging mejorada
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"
  # L√≠mites de recursos (Ollama puede consumir mucha RAM)
  deploy:
    resources:
      limits:
        cpus: '6.0'
        memory: 32G
      reservations:
        cpus: '2.0'
        memory: 8G

# Plantilla para inicializaci√≥n de modelos de Ollama
# Este servicio descarga autom√°ticamente los modelos de IA al iniciar
x-init-ollama: &init-ollama
  image: ollama/ollama:latest
  networks: [ 'genai-network' ]
  container_name: ollama-pull-llama
  volumes:
    - ollama_storage:/root/.ollama # Comparte el mismo volumen que ollama
  entrypoint: /bin/sh # Usa shell para ejecutar comandos
  environment:
    - OLLAMA_HOST=${OLLAMA_HOST_INTERNAL:-ollama}:${OLLAMA_PORT_INTERNAL:-11434} # Conecta con el servicio ollama
  command:
    - "-c"
    - |
      set -e                       # Termina si cualquier comando falla
      echo "Descargando llama3.2..."
      ollama pull llama3.2 || { echo "‚ùå Fall√≥ llama3.2"; exit 1; }

      echo "Descargando llama3.3..."
      ollama pull llama3.3 || { echo "‚ùå Fall√≥ llama3.3"; exit 1; }

      echo "Descargando all-minilm..."
      ollama pull all-minilm || { echo "‚ùå Fall√≥ all-minilm"; exit 1; }

      #echo "Descargando all-minilm:33m..."
      #ollama pull all-minilm:33m || { echo "‚ùå Fall√≥ all-minilm:33m"; exit 1; }

      echo "Descargando deepseek-r1:14b..."
      ollama pull deepseek-r1:14b || { echo "‚ùå Fall√≥ deepseek"; exit 1; }

      echo "Descargando nomic-embed-text..."
      ollama pull nomic-embed-text || { echo "‚ùå Fall√≥ nomic-embed-text"; exit 1; }

      echo "‚úÖ Todos los modelos fueron descargados correctamente"
  # Configuraci√≥n de logging
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"

# =============================================================================
# SERVICIOS PRINCIPALES
# =============================================================================

services:
  # Inicializador de base de datos para Keycloak
  # DESHABILITADO: Causa conflicto con postgres al compartir el mismo volumen
  # postgres ahora ejecuta el script de inicializaci√≥n directamente
  # postgres-init:
  #   image: postgres:16-alpine
  #   container_name: postgres-init
  #   profiles: ["security"]
  #   environment:
  #     - POSTGRES_USER=${POSTGRES_USER}
  #     - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
  #     - POSTGRES_DB=${POSTGRES_DB}
  #   volumes:
  #     - postgres_storage:/var/lib/postgresql/data
  #     - ./scripts/init-keycloak-db.sql:/docker-entrypoint-initdb.d/init-keycloak-db.sql
  #   networks:
  #     - genai-network
  #   command: postgres -c 'max_connections=${POSTGRES_MAX_CONNECTIONS:-200}'
  #   healthcheck:
  #     test: ['CMD-SHELL', 'pg_isready -h localhost -U ${POSTGRES_USER} -d ${POSTGRES_DB}']
  #     interval: 5s
  #     timeout: 5s
  #     retries: 10
  #   logging:
  #     driver: "json-file"
  #     options:
  #       max-size: "10m"
  #       max-file: "3"
  #   deploy:
  #     resources:
  #       limits:
  #         cpus: '2.0'
  #         memory: 4G
  #       reservations:
  #         cpus: '0.5'
  #         memory: 1G

  postgres:
    image: postgres:16-alpine # PostgreSQL 16 con Alpine Linux (m√°s ligero)
    hostname: ${POSTGRES_HOSTNAME:-postgres}
    container_name: postgres
    networks: [ 'genai-network' ]
    restart: unless-stopped
    environment:
      - POSTGRES_USER # Usuario de BD (desde .env)
      - POSTGRES_PASSWORD # Contrase√±a de BD (desde .env)
      - POSTGRES_DB # Nombre de BD (desde .env) - se crea autom√°ticamente
      - POSTGRES_HOST_AUTH_METHOD=scram-sha-256
      # Configuraci√≥n para prevenir transacciones pendientes y locks
      - POSTGRES_INITDB_ARGS=-E UTF8 --locale=C
    volumes:
      - postgres_storage:/var/lib/postgresql/data # Datos persistentes
      - ./scripts/utils/sql/init-keycloak-db.sql:/docker-entrypoint-initdb.d/init-keycloak-db.sql
    # Tiempo de gracia para shutdown limpio (30 segundos)
    stop_grace_period: 30s
    # Comando con configuraci√≥n para manejar mejor los shutdowns
    command: >
      postgres -c shared_buffers=256MB -c max_connections=${POSTGRES_MAX_CONNECTIONS:-200} -c statement_timeout=30000 -c idle_in_transaction_session_timeout=60000 -c lock_timeout=30000
    healthcheck:
      # Verifica que PostgreSQL est√© listo
      test: [ 'CMD-SHELL', 'pg_isready -h localhost -U ${POSTGRES_USER} -d ${POSTGRES_DB}' ]
      interval: 5s
      timeout: 5s
      retries: 10
    # Configuraci√≥n de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # L√≠mites de recursos
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G

  # Base de datos PostgreSQL con extensi√≥n vectorial (para embeddings)
  pgvector:
    image: ankane/pgvector # PostgreSQL con extensi√≥n pgvector
    container_name: pgvector
    networks: [ 'genai-network' ]
    environment:
      POSTGRES_USER: ${PGVECTOR_USER?Variable not set}
      POSTGRES_PASSWORD: ${PGVECTOR_PASSWORD?Variable not set}
      POSTGRES_DB: ${PGVECTOR_DB:-pgvector_db}
    ports:
      - "${PORT_PGVECTOR_HOST:-5433}:${PORT_PGVECTOR_CONTAINER:-5432}"
    restart: unless-stopped
    volumes:
      - pgvector_data:/var/lib/postgresql/data
    # Configuraci√≥n de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # L√≠mites de recursos
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G

  # Interfaz web moderna para chat con IA
  open-webui:
    image: ghcr.io/open-webui/open-webui:v0.7.2 # Versi√≥n actualizada
    container_name: open-webui
    profiles: [ "chat-ai" ] # Perfil de chat con IA (requiere --profile security para Keycloak)
    ports:
      - "${PORT_OPEN_WEBUI_HOST:-3000}:${PORT_OPEN_WEBUI_CONTAINER:-8080}"
    environment:
      # Redis Cache Config
      # Redis Cache Config
      # Redis Cache Config
      - CACHE_TYPE=${OPEN_WEBUI_CACHE_TYPE:-redis}
      - REDIS_URL=${OPEN_WEBUI_REDIS_URL:-redis://redis:6379/0}
      - RAG_SYSTEM_CONTEXT=${OPEN_WEBUI_RAG_SYSTEM_CONTEXT:-true}
      - USE_EMBEDDING_CACHE=${OPEN_WEBUI_USE_EMBEDDING_CACHE:-true}
      # OLLAMA_BASE_URL: URL interna para conectar con Ollama desde el contenedor
      - OLLAMA_BASE_URL=${OLLAMA_URL_INTERNAL:-http://ollama:11434}
      - USER_AGENT=${OPEN_WEBUI_USER_AGENT:-OpenWebUI/0.6.13}
      - CORS_ALLOW_ORIGIN=${OPEN_WEBUI_URL_PUBLIC:-http://localhost:3000}
      # Configuraci√≥n de usuarios y acceso
      - ENABLE_SIGNUP=${OPEN_WEBUI_ENABLE_SIGNUP:-true} # Permitir registro de usuarios
      - ENABLE_LOGIN_FORM=${OPEN_WEBUI_ENABLE_LOGIN_FORM:-true} # Permitir login con formulario
      # Configuraci√≥n OIDC/OAuth con Keycloak
      - ENABLE_OAUTH_SSO=${OPEN_WEBUI_ENABLE_OAUTH_SSO:-true}
      - ENABLE_OAUTH_SIGNUP=${OPEN_WEBUI_ENABLE_OAUTH_SIGNUP:-true} # Permitir registro autom√°tico de usuarios OAuth
      - OAUTH_CLIENT_ID=${OPEN_WEBUI_OAUTH_CLIENT_ID:-open-webui}
      - OAUTH_CLIENT_SECRET=${OPEN_WEBUI_OAUTH_CLIENT_SECRET}
      - OAUTH_PROVIDER_NAME=${OPEN_WEBUI_OAUTH_PROVIDER_NAME:-Keycloak}
      # Configuraci√≥n OIDC - LIMITACI√ìN CONOCIDA DE OPEN WEBUI
      # Problema: Open WebUI usa URLs del discovery document (localhost:8080) 
      # en lugar de las URLs expl√≠citas (keycloak:8080), causando error 405
      # Esto es una limitaci√≥n de Open WebUI que no respeta URLs expl√≠citas
      # cuando hay un discovery document configurado
      - OPENID_ENABLED=${OPEN_WEBUI_OAUTH_ENABLED:-true} # OpenID usa variables OAUTH_ (consolidado seg√∫n documentaci√≥n)
      - OPENID_CLIENT_ID=${OPEN_WEBUI_OAUTH_CLIENT_ID:-open-webui} # OpenID usa variables OAUTH_ (consolidado seg√∫n documentaci√≥n)
      - OPENID_CLIENT_SECRET=${OPEN_WEBUI_OAUTH_CLIENT_SECRET} # OpenID usa variables OAUTH_ (consolidado seg√∫n documentaci√≥n)
      # FAKE DISCOVERY: Soluci√≥n robusta para split routing (Browser vs Backend)
      # Apunta a un archivo JSON local (montado) que define URLs diferentes para Auth (localhost) y Token (keycloak)
      - OPENID_PROVIDER_URL=http://127.0.0.1:8080/static/oidc-config.json # Fake Discovery endpoint
      - OPENID_REDIRECT_URI=${OPEN_WEBUI_URL_PUBLIC:-http://localhost:3000}/oauth/oidc/callback
      - OPENID_SCOPES=${OPEN_WEBUI_OAUTH_SCOPES:-openid profile email}
      - OPENID_CLIENT_SECRET=${KEYCLOAK_CLIENT_SECRET_OPEN_WEBUI}
      - OPENID_SCOPES=openid email profile roles
      # Verified via test-keycloak-claims: roles are at top level
      - OPENID_ROLES_CLAIM=roles
      # Role mapping
      - OPENID_ADMIN_ROLE=openwebui-admin
      - DEFAULT_USER_ROLE=user # Auto-activate new users (ignore pending state)
      - ENABLE_SIGNUP=true
      - OPENID_SIGN_OUT_REDIRECT_URL=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/logout
    volumes:
      - open_webui_storage:/app/backend/data # Datos persistentes
      - ./config/open-webui-oidc/oidc-config.json:/app/backend/open_webui/static/oidc-config.json:ro # Fake Discovery JSON
      - ./config/open-webui-oidc/userinfo.json:/app/backend/open_webui/static/userinfo.json:ro # Fake UserInfo response
      #- /mnt/e/docker/app/open-webui/backend/data:/app/backend/data  # Montaje local (comentado)
    networks:
      - genai-network
    # extra_hosts eliminado (no funcion√≥ para mapear localhost)

    depends_on:
      keycloak:
        condition: service_healthy # Espera a que Keycloak est√© listo (requiere --profile security)
      keycloak-init:
        condition: service_completed_successfully
      # Espera a que los modelos LLM est√©n descargados antes de iniciar
      ollama-pull-llama-gpu:
        condition: service_completed_successfully
    healthcheck:
      # Verifica que Open WebUI est√© funcionando (usando IP porque localhost apunta al gateway ahora)
      test: [ "CMD", "curl", "-f", "http://127.0.0.1:8080/healthz" ]
      interval: 10s
      timeout: 5s
      retries: 5
    # Configuraci√≥n de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # L√≠mites de recursos
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G

  # Servicio de importaci√≥n de datos para n8n (se ejecuta una vez al inicio)
  n8n-import:
    <<: *service-n8n # Usa la plantilla n8n
    hostname: n8n-import
    container_name: n8n-import
    networks: [ 'genai-network' ]
    entrypoint: /bin/sh # Usa shell para ejecutar comandos de importaci√≥n
    command:
      - "-c"
      - "n8n import:credentials --separate --input=/data/credentials && n8n import:workflow --separate --input=/data/workflows"
    volumes:
      - n8n_data:/data # Datos de importaci√≥n/exportaci√≥n
    depends_on:
      postgres:
        condition: service_healthy # Espera a que PostgreSQL est√© listo
    healthcheck:
      # Verifica que n8n-import est√© funcionando
      test: [ "CMD", "curl", "-f", "http://n8n:5678/healthz" ]
      interval: 10s
      timeout: 5s
      retries: 5

  # Servicio principal de n8n (plataforma de automatizaci√≥n)
  n8n:
    <<: *service-n8n # Usa la plantilla n8n
    hostname: n8n
    container_name: n8n
    profiles: [ "automation" ] # Perfil de automatizaci√≥n (requiere --profile security para Keycloak)
    restart: unless-stopped
    ports:
      - "${PORT_N8N_HOST:-5678}:${PORT_N8N_CONTAINER:-5678}"
    environment:
      - N8N_RUNNERS_ENABLED=${N8N_RUNNERS_ENABLED:-true}
      - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=${N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS:-true}
      - N8N_BASIC_AUTH_ACTIVE=false
      # Configuraci√≥n OIDC/OAuth con Keycloak
      - N8N_AUTH_TYPE=${N8N_AUTH_TYPE:-oidc}
      - N8N_OIDC_ISSUER=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}
      - N8N_OIDC_CLIENT_ID=${N8N_OIDC_CLIENT_ID:-n8n}
      - N8N_OIDC_CLIENT_SECRET=${N8N_OIDC_CLIENT_SECRET?Variable not set}
      # URLs expl√≠citas - authorization usa localhost (navegador), token/userinfo usan keycloak (interno)
      - N8N_OIDC_AUTHORIZATION_URL=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/auth
      - N8N_OIDC_TOKEN_URL=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/token
      - N8N_OIDC_USER_INFO_URL=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/userinfo
      - N8N_OIDC_REDIRECT_URI=${N8N_URL_PUBLIC:-http://localhost:5678}/rest/oauth2-credential/callback
      - N8N_OIDC_SCOPES=${N8N_OIDC_SCOPES:-openid profile email}
      - N8N_OIDC_DISPLAY_NAME=${N8N_OIDC_DISPLAY_NAME:-Keycloak}
      # Redis Config (for Queue Mode readiness and Workflow nodes)
      # These specific ENV vars are standard for n8n queue mode or can be used inside workflows
      - QUEUE_BULL_REDIS_HOST=${N8N_REDIS_HOST:-redis}
      - QUEUE_BULL_REDIS_PORT=${N8N_REDIS_PORT:-6379}
      - QUEUE_BULL_REDIS_DB=${N8N_REDIS_DB:-1}
      - REDIS_HOST=${N8N_REDIS_HOST:-redis} # For use in workflows via expression
      - REDIS_PORT=${N8N_REDIS_PORT:-6379} # For use in workflows via expression
      - Redis_DB=${N8N_REDIS_DB:-1} # For      - GENERIC_TIMEZONE=${TZ:-UTC}
      - TZ=${TZ:-UTC}
      # Variable para facilitar la conexi√≥n a la cola de Ollama (HAProxy)
      - OLLAMA_QUEUE_URL=http://haproxy/ollama
    volumes:
      - n8n_storage:/home/node/.n8n # Datos persistentes de n8n
      - n8n_data:/data # Datos de importaci√≥n/exportaci√≥n
      - shared_data:/data/shared # Datos compartidos
    depends_on:
      postgres:
        condition: service_healthy # Espera a que PostgreSQL est√© listo
      n8n-import:
        condition: service_completed_successfully # Espera a que termine la importaci√≥n
      keycloak:
        condition: service_healthy # Espera a que Keycloak est√© listo (requiere --profile security)
      keycloak-init:
        condition: service_completed_successfully
    healthcheck:
      # Verifica que n8n est√© funcionando
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:5678/healthz || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5

  # Base de datos vectorial Qdrant (para embeddings y b√∫squeda sem√°ntica)
  qdrant:
    image: qdrant/qdrant
    hostname: qdrant
    container_name: qdrant
    networks: [ 'genai-network' ]
    restart: unless-stopped
    ports:
      - "${PORT_QDRANT_HOST:-6333}:${PORT_QDRANT_CONTAINER:-6333}"
    volumes:
      - qdrant_storage:/qdrant/storage # Datos persistentes
    healthcheck:
      # Verifica que Qdrant est√© funcionando
      test: [ "CMD-SHELL", "for pid in /proc/*/comm; do [ -f \"$$pid\" ] && grep -q qdrant \"$$pid\" 2>/dev/null && exit 0; done; exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    # Configuraci√≥n de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # L√≠mites de recursos
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G

  # =============================================================================
  # SERVICIOS DE OLLAMA (DIFERENTES PERFILES)
  # =============================================================================
  # Estos servicios usan perfiles para activar solo uno seg√∫n el hardware disponible

  # Perfil CPU: Ollama usando solo CPU (m√°s lento pero funciona en cualquier m√°quina)
  ollama-cpu:
    profiles: [ "cpu" ] # Solo se activa con --profile cpu
    <<: *service-ollama # Usa la plantilla ollama

  # Perfil GPU NVIDIA: Ollama con aceleraci√≥n GPU NVIDIA
  ollama-gpu:
    profiles: [ "gpu-nvidia" ] # Solo se activa con --profile gpu-nvidia
    <<: *service-ollama # Usa la plantilla ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia # Usa driver NVIDIA
              count: 1 # Usa 1 GPU
              capabilities: [ gpu ] # Habilita capacidades GPU

  # Perfil GPU AMD: Ollama con aceleraci√≥n GPU AMD
  ollama-gpu-amd:
    profiles: [ "gpu-amd" ] # Solo se activa con --profile gpu-amd
    <<: *service-ollama
    image: ollama/ollama:rocm # Imagen con soporte ROCm (AMD)
    devices:
      - "/dev/kfd" # Dispositivo AMD GPU
      - "/dev/dri" # Dispositivo de renderizado

  # =============================================================================
  # SERVICIOS DE INICIALIZACI√ìN DE MODELOS (DIFERENTES PERFILES)
  # =============================================================================
  # Estos servicios descargan los modelos de IA seg√∫n el perfil activado

  # Descarga de modelos para CPU
  # ollama-pull-llama-cpu:
  #   profiles: ["cpu"]
  #   <<: *init-ollama               # Usa la plantilla de inicializaci√≥n
  #   depends_on:
  #     - ollama-cpu                 # Espera a que ollama-cpu est√© listo

  # Descarga de modelos para GPU NVIDIA
  ollama-pull-llama-gpu:
    profiles: [ "gpu-nvidia" ]
    <<: *init-ollama # Usa la plantilla de inicializaci√≥n
    depends_on:
      ollama-gpu:
        condition: service_healthy # Espera a que ollama-gpu est√© healthy

  # Descarga de modelos para GPU AMD
  # ollama-pull-llama-gpu-amd:
  #   profiles: [gpu-amd]
  #   <<: *init-ollama               # Usa la plantilla de inicializaci√≥n
  #   image: ollama/ollama:rocm      # Imagen con soporte ROCm
  #   depends_on:
  #    - ollama-gpu-amd              # Espera a que ollama-gpu-amd est√© listo


  # =============================================================================
  # SERVICIOS DE MONITOREO Y MANTENIMIENTO (OPCIONALES)
  # =============================================================================
  # Estos servicios ayudan a monitorear y mantener el stack

  # Prometheus - Recolector de m√©tricas
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    profiles: [ "monitoring" ]
    ports:
      - "${PORT_PROMETHEUS_HOST:-9090}:${PORT_PROMETHEUS_CONTAINER:-9090}"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus_rules_data:/etc/prometheus/rules/custom:ro # Reglas personalizadas persistentes
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
      - '--web.external-url=/prometheus/'
      - '--web.route-prefix=/prometheus/'
    networks:
      - monitoring-network
      - genai-network
    healthcheck:
      test: [ "CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy" ]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

  # Grafana - Dashboards y visualizaci√≥n
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    profiles: [ "monitoring" ]
    ports:
      - "${PORT_GRAFANA_HOST:-3001}:${PORT_GRAFANA_CONTAINER:-3000}"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./monitoring/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/config/grafana.ini:/etc/grafana/grafana.ini:ro
      # Volumen para dashboards personalizados creados por usuarios
      - grafana_provisioning_data:/var/lib/grafana/dashboards/custom:ro
    environment:
      - GF_DATABASE_TYPE=postgres
      - GF_DATABASE_HOST=postgres:5432
      - GF_DATABASE_NAME=${GRAFANA_DB_NAME:-grafana}
      - GF_DATABASE_USER=${GRAFANA_DB_USER:-grafana}
      - GF_DATABASE_PASSWORD=${GRAFANA_DB_PASSWORD:-grafana}
      - GF_DATABASE_SSL_MODE=disable
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD?Variable not set}
      - GF_LOG_LEVEL=debug
      - GF_SECURITY_ADMIN_EMAIL=${GRAFANA_ADMIN_EMAIL?Variable not set}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_AUTH_GENERIC_OAUTH_ENABLED=${GRAFANA_AUTH_GENERIC_OAUTH_ENABLED:-true}
      - GF_AUTH_GENERIC_OAUTH_NAME=${GRAFANA_OAUTH_NAME:-Keycloak}
      - GF_AUTH_GENERIC_OAUTH_CLIENT_ID=${GRAFANA_OAUTH_CLIENT_ID:-grafana}
      - GF_AUTH_GENERIC_OAUTH_CLIENT_SECRET=${GRAFANA_OAUTH_CLIENT_SECRET}
      - GF_AUTH_GENERIC_OAUTH_SCOPES=${GRAFANA_OAUTH_SCOPES:-openid profile email}
      - GF_AUTH_GENERIC_OAUTH_ALLOW_ASSIGN_GRAFANA_ADMIN=true
      - GF_AUTH_GENERIC_OAUTH_ALLOW_OAUTH_SIGNIN_WITH_EMAIL_LOOKUP=true
      # AUTH_URL debe usar localhost porque el navegador del usuario necesita acceder

      - GF_AUTH_GENERIC_OAUTH_AUTH_URL=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/auth
      # TOKEN_URL y API_URL pueden usar keycloak:8080 porque Grafana las llama desde dentro del contenedor
      - GF_AUTH_GENERIC_OAUTH_TOKEN_URL=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/token
      - GF_AUTH_GENERIC_OAUTH_API_URL=${KEYCLOAK_URL_INTERNAL:-http://keycloak:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/userinfo
      - GF_AUTH_GENERIC_OAUTH_SKIP_ORG_ROLE_SYNC=${GRAFANA_SKIP_ORG_ROLE_SYNC:-true}
      # Role Mapping: Keycloak Roles -> Grafana Roles
      # Maps 'grafana-admin' -> Admin, 'grafana-editor' -> Editor, others -> Viewer
      # Verified via Token Dump: roles are available at top level 'roles' claim
      - GF_AUTH_GENERIC_OAUTH_ROLE_ATTRIBUTE_PATH=contains(roles[*], 'grafana-admin') && 'Admin' || contains(roles[*], 'grafana-editor') && 'Editor' || 'Viewer'
      # SIGNOUT_REDIRECT_URL debe usar localhost porque el navegador del usuario necesita acceder
      - GF_AUTH_SIGNOUT_REDIRECT_URL=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}/realms/${KEYCLOAK_REALM:-master}/protocol/openid-connect/logout
      - GF_SERVER_ROOT_URL=${GRAFANA_URL_PUBLIC:-http://localhost/grafana}
      - GF_SERVER_SERVE_FROM_SUB_PATH=true
      - GF_USERS_AUTO_LOGIN=${GRAFANA_USERS_AUTO_LOGIN:-false}
      - GF_AUTH_DISABLE_LOGIN_FORM=${GRAFANA_AUTH_DISABLE_LOGIN_FORM:-true} # Solo Keycloak OAuth (m√°s seguro)
    networks:
      - monitoring-network
      - genai-network
    depends_on:
      prometheus:
        condition: service_healthy
      keycloak:
        condition: service_healthy
      grafana-db-init:
        condition: service_completed_successfully
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

  # AlertManager - Gesti√≥n de alertas
  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    profiles: [ "monitoring" ]
    ports:
      - "${PORT_ALERTMANAGER_HOST:-9093}:${PORT_ALERTMANAGER_CONTAINER:-9093}"
    volumes:
      - ./monitoring/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=/alertmanager/'
      - '--web.route-prefix=/alertmanager/'
    networks:
      - monitoring-network
      - genai-network
    healthcheck:
      test: [ "CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9093/-/healthy" ]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M

  # Servicio de backup autom√°tico (Backup Runner)
  backup:
    image: docker:cli
    container_name: backup
    profiles: [ "monitoring" ]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro # Control de Docker (DooD)
      - ./:/app # Montar el proyecto
      - ./backups:/app/backups # Persistencia de backups (Bind Mount)
    working_dir: /app
    networks:
      - backend-network
      - genai-network
    environment:
      - HOST_BACKUP_PATH=${PWD}/backups
    entrypoint: [ "/bin/sh", "-c" ]
    command:
      - |
        # Instalar dependencias necesarias (bash para el script)
        apk add --no-cache bash

        echo "Iniciando Backup Runner..."
        echo "Script: /app/scripts/backup-manager.sh"

        # Bucle de ejecuci√≥n diaria
        while true; do
          echo "Ejecutando backup autom√°tico: $$(date)"
          
          # Ejecutar el script consolidado
          # Usamos 'backup --verify' para seguridad
          /bin/bash /app/scripts/backup-manager.sh backup --verify
          
          echo "Pr√≥ximo backup en 24 horas..."
          sleep 86400
        done
    # Configuraci√≥n de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # L√≠mites de recursos
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Servicio de herramientas de desarrollo
  dev-tools:
    image: alpine:latest
    container_name: dev-tools
    profiles: [ "dev" ] # Solo se activa con --profile dev
    volumes:
      - .:/workspace
    working_dir: /workspace
    command: sh -c "apk add --no-cache curl jq && tail -f /dev/null"
    # Configuraci√≥n de logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # L√≠mites de recursos
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Node Exporter - M√©tricas del host
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    profiles: [ "monitoring" ]
    ports:
      - "${PORT_NODE_EXPORTER_HOST:-9100}:${PORT_NODE_EXPORTER_CONTAINER:-9100}"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - monitoring-network
    healthcheck:
      test: [ "CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9100/metrics" ]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # cAdvisor - M√©tricas de contenedores
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    profiles: [ "monitoring" ]
    ports:
      - "${PORT_CADVISOR_HOST:-8082}:${PORT_CADVISOR_CONTAINER:-8080}"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro # Necesario para descubrir contenedores
    networks:
      - monitoring-network
    healthcheck:
      test: [ "CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8080/healthz" ]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M

  # PostgreSQL Exporter - M√©tricas de PostgreSQL
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: postgres-exporter
    profiles: [ "monitoring" ]
    environment:
      DATA_SOURCE_NAME: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?sslmode=disable"
    ports:
      - "${PORT_POSTGRES_EXPORTER_HOST:-9187}:${PORT_POSTGRES_EXPORTER_CONTAINER:-9187}"
    networks:
      - monitoring-network
      - genai-network # Necesario para conectarse a PostgreSQL
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9187/metrics" ]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # NVIDIA GPU Exporter - M√©tricas de GPU NVIDIA
  nvidia-exporter:
    image: nvidia/dcgm-exporter:latest
    container_name: nvidia-exporter
    profiles: [ "monitoring", "gpu-nvidia" ] # Solo se activa con monitoring y gpu-nvidia
    ports:
      - "${PORT_NVIDIA_EXPORTER_HOST:-9400}:${PORT_NVIDIA_EXPORTER_CONTAINER:-9400}"
    networks:
      - monitoring-network
    healthcheck:
      test: [ "CMD-SHELL", "grep -q \":24B8\" /proc/net/tcp6 || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]

  # Ollama Exporter - M√©tricas espec√≠ficas de Ollama
  ollama-exporter:
    image: python:3.11-alpine
    container_name: ollama-exporter
    profiles: [ "monitoring" ]
    ports:
      - "${PORT_OLLAMA_EXPORTER_HOST:-9888}:${PORT_OLLAMA_EXPORTER_CONTAINER:-9888}"
    volumes:
      - ./scripts/utils/exporters/ollama-exporter.py:/app/ollama-exporter.py:ro
    networks:
      - monitoring-network
      - genai-network # Necesario para conectarse a Ollama
    environment:
      - OLLAMA_HOST=${OLLAMA_HOST_INTERNAL:-ollama}:${OLLAMA_PORT_INTERNAL:-11434}
      - EXPORTER_PORT=9888
      - SCRAPE_INTERVAL=15
    command: python3 /app/ollama-exporter.py
    # Depende de cualquier servicio Ollama que est√© activo (gpu-nvidia o cpu)
    healthcheck:
      test: [ "CMD", "wget", "--quiet", "--tries=1", "--spider", "http://127.0.0.1:9888/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 64M

  # n8n Exporter - M√©tricas espec√≠ficas de n8n
  n8n-exporter:
    image: python:3.11-alpine
    container_name: n8n-exporter
    profiles: [ "monitoring" ]
    ports:
      - "${PORT_N8N_EXPORTER_HOST:-9889}:${PORT_N8N_EXPORTER_CONTAINER:-9889}"
    volumes:
      - ./scripts/utils/exporters/n8n-exporter.py:/app/n8n-exporter.py:ro
    networks:
      - monitoring-network
      - genai-network # Necesario para conectarse a n8n
    environment:
      - N8N_HOST=${N8N_HOST_INTERNAL:-n8n}:${PORT_N8N_CONTAINER:-5678}
      - EXPORTER_PORT=9889
      - SCRAPE_INTERVAL=15
    command: python3 /app/n8n-exporter.py
    # No depende de n8n directamente para permitir que el exporter funcione
    # incluso si n8n no est√° corriendo (simplemente reportar√° n8n_up=0)
    healthcheck:
      test: [ "CMD", "wget", "--quiet", "--tries=1", "--spider", "http://127.0.0.1:9889/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Open WebUI Exporter - M√©tricas espec√≠ficas de Open WebUI
  openwebui-exporter:
    image: python:3.11-alpine
    container_name: openwebui-exporter
    profiles: [ "monitoring" ]
    ports:
      - "${PORT_OPENWEBUI_EXPORTER_HOST:-9890}:${PORT_OPENWEBUI_EXPORTER_CONTAINER:-9890}"
    volumes:
      - ./scripts/utils/exporters/openwebui-exporter.py:/app/openwebui-exporter.py:ro
    networks:
      - monitoring-network
      - genai-network # Necesario para conectarse a Open WebUI
    environment:
      - OPEN_WEBUI_HOST=${OPEN_WEBUI_HOST_INTERNAL:-open-webui}:${PORT_OPEN_WEBUI_CONTAINER:-8080}
      - EXPORTER_PORT=9890
      - SCRAPE_INTERVAL=15
    command: python3 /app/openwebui-exporter.py
    # No depende de open-webui directamente para permitir que el exporter funcione
    # incluso si open-webui no est√° corriendo (simplemente reportar√° openwebui_up=0)
    healthcheck:
      test: [ "CMD", "wget", "--quiet", "--tries=1", "--spider", "http://127.0.0.1:9890/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 64M

  # =============================================================================
  # SERVICIOS DE INFRAESTRUCTURA
  # =============================================================================
  # Servicios que mejoran el rendimiento y escalabilidad

  # Redis - Cache y sesiones
  redis:
    image: redis:alpine
    container_name: redis
    profiles: [ "infrastructure" ]
    ports:
      - "${PORT_REDIS_HOST:-6379}:${PORT_REDIS_CONTAINER:-6379}"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    networks:
      - backend-network
      - genai-network
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.25'
          memory: 512M

  # Redis Exporter - M√©tricas de Redis para Prometheus
  redis-exporter:
    image: oliver006/redis_exporter:alpine
    container_name: redis-exporter
    profiles: [ "monitoring" ]
    environment:
      - REDIS_ADDR=redis:6379
    ports:
      - "${PORT_REDIS_EXPORTER_HOST:-9121}:${PORT_REDIS_EXPORTER_CONTAINER:-9121}"
    networks:
      - monitoring-network
      - backend-network
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9121/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 32M

  # HAProxy - Load Balancer
  haproxy:
    image: haproxy:latest
    container_name: haproxy
    profiles: [ "infrastructure" ]
    ports:
      - "${PORT_HAPROXY_HTTP_HOST:-80}:${PORT_HAPROXY_HTTP_CONTAINER:-80}"
      - "${PORT_HAPROXY_HTTPS_HOST:-443}:${PORT_HAPROXY_HTTPS_CONTAINER:-443}"
    volumes:
      - ./haproxy/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
      - haproxy_data:/var/lib/haproxy
    networks:
      - frontend-network
      - backend-network
      - genai-network
      - monitoring-network # Agregado para poder resolver Grafana y Prometheus
    healthcheck:
      test: [ "CMD", "haproxy", "-c", "-f", "/usr/local/etc/haproxy/haproxy.cfg" ]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M

  # =============================================================================
  # SERVICIOS DE SEGURIDAD Y AUTENTICACI√ìN
  # =============================================================================
  # Servicios para mejorar la seguridad del stack

  # Keycloak - Autenticaci√≥n centralizada
  keycloak:
    image: quay.io/keycloak/keycloak:latest
    container_name: keycloak
    profiles: [ "security", "gen-ai", "monitoring", "ci-cd" ]
    environment:
      - KEYCLOAK_ADMIN=${KEYCLOAK_ADMIN_USER?Variable not set}
      - KEYCLOAK_ADMIN_PASSWORD=${KEYCLOAK_ADMIN_PASSWORD?Variable not set}
      - KC_DB=${KEYCLOAK_DB_TYPE:-postgres}
      - KC_DB_URL=jdbc:postgresql://${POSTGRES_HOST_INTERNAL:-postgres}:${POSTGRES_PORT_INTERNAL:-5432}/${KEYCLOAK_DB_NAME:-keycloak}?connectTimeout=10&socketTimeout=60
      - KC_DB_USERNAME=${POSTGRES_USER}
      - KC_DB_PASSWORD=${POSTGRES_PASSWORD}
      # Configuraci√≥n de pool de conexiones para prevenir transacciones pendientes
      # IMPORTANTE: Reducir INITIAL_SIZE para evitar m√∫ltiples conexiones compitiendo por el lock al inicio
      - KC_DB_POOL_INITIAL_SIZE=${KEYCLOAK_DB_POOL_INITIAL_SIZE:-2}
      - KC_DB_POOL_MIN_SIZE=${KEYCLOAK_DB_POOL_MIN_SIZE:-2}
      - KC_DB_POOL_MAX_SIZE=${KEYCLOAK_DB_POOL_MAX_SIZE:-20}
      - KC_HOSTNAME=${HOSTNAME_PUBLIC:-localhost}
      - KC_HOSTNAME_PORT=${PORT_KEYCLOAK_HOST:-8080}
      - KC_HOSTNAME_STRICT=${KEYCLOAK_HOSTNAME_STRICT:-false}
      - KC_HTTP_ENABLED=${KEYCLOAK_HTTP_ENABLED:-true}
      - KC_HEALTH_ENABLED=${KEYCLOAK_HEALTH_ENABLED:-true}
      # Configuraci√≥n para cookies en contexto HTTP (no seguro)
      - KC_HTTP_RELATIVE_PATH=${KEYCLOAK_HTTP_RELATIVE_PATH:-/}
      - KC_PROXY=${KEYCLOAK_PROXY:-edge}
      - KC_PROXY_ADDRESS_FORWARDING=${KEYCLOAK_PROXY_ADDRESS_FORWARDING:-true}
      - KC_METRICS_ENABLED=true
    ports:
      - "${PORT_KEYCLOAK_HOST:-8080}:${PORT_KEYCLOAK_CONTAINER:-8080}"
    volumes:
      - keycloak_data:/opt/keycloak/data
    networks:
      - security-network
      - backend-network
      - genai-network
    depends_on:
      postgres:
        condition: service_healthy
      keycloak-db-init:
        condition: service_completed_successfully
    # Tiempo de gracia para shutdown limpio (30 segundos)
    stop_grace_period: 30s
    command: start-dev --http-enabled=true --hostname-strict=false --metrics-enabled=true
    healthcheck:
      # Keycloak health check: verificar que el proceso est√© corriendo Y que el puerto responda
      # Keycloak no tiene curl/wget, pero podemos verificar:
      # 1. Que el proceso keycloak est√© corriendo (verificaci√≥n principal)
      # 2. Que el puerto 8080 responda a conexiones TCP (verificaci√≥n secundaria)
      # Usamos verificaci√≥n simple pero confiable sin dependencias externas
      test: [ "CMD-SHELL", "test -f /proc/1/cmdline && cat /proc/1/cmdline | grep -q keycloak && /bin/sh -c 'exec 3<>/dev/tcp/localhost/8080 2>/dev/null && echo -e \"GET / HTTP/1.1\\r\\nHost: localhost\\r\\nConnection: close\\r\\n\\r\\n\" >&3 && head -1 <&3 | grep -q \"HTTP\"' || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Inicializador de BD de Keycloak - Crea BD ANTES de que Keycloak inicie
  keycloak-db-init:
    image: postgres:16-alpine
    container_name: keycloak-db-init
    profiles: [ "security", "gen-ai", "monitoring", "ci-cd" ]
    networks:
      - genai-network
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB:-postgres}
      - KEYCLOAK_DB_NAME=${KEYCLOAK_DB_NAME:-keycloak}
      - PGSSLMODE=disable
    entrypoint: /bin/sh
    command:
      - "-c"
      - |
        set -e
        echo "üîß Verificando base de datos de Keycloak..."
        echo ""

        # Esperar a que PostgreSQL est√© listo
        until PGPASSWORD="$${POSTGRES_PASSWORD}" psql -h postgres -U "$${POSTGRES_USER}" -d "$${POSTGRES_DB}" -c "SELECT 1;" > /dev/null 2>&1; do
          echo "   ‚è≥ Esperando a que PostgreSQL est√© listo..."
          sleep 2
        done

        # Verificar si la BD existe
        DB_EXISTS=$$(PGPASSWORD="$${POSTGRES_PASSWORD}" psql -h postgres -U "$${POSTGRES_USER}" -d "$${POSTGRES_DB}" -tAc "SELECT 1 FROM pg_database WHERE datname = '$${KEYCLOAK_DB_NAME}';" 2>/dev/null || echo "0")

        if [ "$$DB_EXISTS" != "1" ]; then
          echo "   ‚úÖ Creando base de datos '$${KEYCLOAK_DB_NAME}'..."
          PGPASSWORD="$${POSTGRES_PASSWORD}" psql -h postgres -U "$${POSTGRES_USER}" -d "$${POSTGRES_DB}" -c "CREATE DATABASE $${KEYCLOAK_DB_NAME} OWNER $${POSTGRES_USER};" 2>/dev/null || true
          echo "   ‚úÖ Base de datos creada (Keycloak crear√° la estructura autom√°ticamente)"
        else
          echo "   ‚úÖ Base de datos '$${KEYCLOAK_DB_NAME}' ya existe"
        fi
        echo ""
        echo "‚úÖ Base de datos lista para Keycloak"
    depends_on:
      postgres:
        condition: service_healthy
    restart: "no" # Solo se ejecuta una vez
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Inicializador de BD de Grafana - Crea BD ANTES de que Grafana inicie
  grafana-db-init:
    image: postgres:16-alpine
    container_name: grafana-db-init
    profiles: [ "monitoring" ]
    networks:
      - genai-network
    environment:
      - POSTGRES_USER=${POSTGRES_USER?Variable not set}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD?Variable not set}
      - POSTGRES_DB=${POSTGRES_DB:-postgres}
      - GRAFANA_DB_NAME=${GRAFANA_DB_NAME:-grafana}
      - GRAFANA_DB_USER=${GRAFANA_DB_USER:-grafana}
      - GRAFANA_DB_PASSWORD=${GRAFANA_DB_PASSWORD?Variable not set}
      - PGSSLMODE=disable
    entrypoint: /bin/sh
    command:
      - "-c"
      - |
        set -e
        echo "üîß Verificando base de datos de Grafana..."
        echo ""

        # Esperar a que PostgreSQL est√© listo
        until PGPASSWORD="$${POSTGRES_PASSWORD}" psql -h postgres -U "$${POSTGRES_USER}" -d "$${POSTGRES_DB}" -c "SELECT 1;" > /dev/null 2>&1; do
          echo "   ‚è≥ Esperando a que PostgreSQL est√© listo..."
          sleep 2
        done

        # Verificar si el usuario existe
        USER_EXISTS=$$(PGPASSWORD="$${POSTGRES_PASSWORD}" psql -h postgres -U "$${POSTGRES_USER}" -d "$${POSTGRES_DB}" -tAc "SELECT 1 FROM pg_roles WHERE rolname='$${GRAFANA_DB_USER}'" 2>/dev/null || echo "0")

        if [ "$$USER_EXISTS" != "1" ]; then
           echo "   ‚úÖ Creando usuario '$${GRAFANA_DB_USER}'..."
           PGPASSWORD="$${POSTGRES_PASSWORD}" psql -h postgres -U "$${POSTGRES_USER}" -d "$${POSTGRES_DB}" -c "CREATE USER $${GRAFANA_DB_USER} WITH PASSWORD '$${GRAFANA_DB_PASSWORD}';" 2>/dev/null || true
        else
           echo "   ‚úÖ Usuario '$${GRAFANA_DB_USER}' ya existe"
        fi

        # Verificar si la BD existe
        DB_EXISTS=$$(PGPASSWORD="$${POSTGRES_PASSWORD}" psql -h postgres -U "$${POSTGRES_USER}" -d "$${POSTGRES_DB}" -tAc "SELECT 1 FROM pg_database WHERE datname = '$${GRAFANA_DB_NAME}';" 2>/dev/null || echo "0")

        if [ "$$DB_EXISTS" != "1" ]; then
          echo "   ‚úÖ Creando base de datos '$${GRAFANA_DB_NAME}'..."
          PGPASSWORD="$${POSTGRES_PASSWORD}" psql -h postgres -U "$${POSTGRES_USER}" -d "$${POSTGRES_DB}" -c "CREATE DATABASE $${GRAFANA_DB_NAME} OWNER $${GRAFANA_DB_USER};" 2>/dev/null || true
          echo "   ‚úÖ Base de datos creada"
        else
          echo "   ‚úÖ Base de datos '$${GRAFANA_DB_NAME}' ya existe"
        fi
        echo ""
        echo "‚úÖ Base de datos lista para Grafana"
    depends_on:
      postgres:
        condition: service_healthy
    restart: "no" # Solo se ejecuta una vez
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Inicializador de clientes Keycloak - Crea clientes OIDC DESPU√âS de que Keycloak est√© listo
  keycloak-init:
    image: alpine:latest
    container_name: keycloak-init
    profiles: [ "security", "gen-ai", "monitoring", "ci-cd" ]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - genai-network
      - security-network
    environment:
      - KEYCLOAK_ADMIN_USER=${KEYCLOAK_ADMIN_USER?Variable not set}
      - KEYCLOAK_ADMIN_PASSWORD=${KEYCLOAK_ADMIN_PASSWORD?Variable not set}
      - KEYCLOAK_REALM=${KEYCLOAK_REALM:-master}
      - GRAFANA_URL_PUBLIC=${GRAFANA_URL_PUBLIC:-http://localhost/grafana}
      - N8N_URL_PUBLIC=${N8N_URL_PUBLIC:-http://localhost:5678}
      - OPEN_WEBUI_URL_PUBLIC=${OPEN_WEBUI_URL_PUBLIC:-http://localhost:3000}
      - JENKINS_URL_PUBLIC=${JENKINS_URL_PUBLIC:-http://localhost:8081}
      - GRAFANA_OAUTH_CLIENT_SECRET=${GRAFANA_OAUTH_CLIENT_SECRET}
      - N8N_OIDC_CLIENT_SECRET=${N8N_OIDC_CLIENT_SECRET}
      - OPEN_WEBUI_OAUTH_CLIENT_SECRET=${OPEN_WEBUI_OAUTH_CLIENT_SECRET}
      - JENKINS_OIDC_CLIENT_SECRET=${JENKINS_OIDC_CLIENT_SECRET}
      - KEYCLOAK_ADMIN_EMAIL=${KEYCLOAK_ADMIN_EMAIL?Variable not set}
      - KEYCLOAK_ADMIN_FIRST_NAME=${KEYCLOAK_ADMIN_FIRST_NAME?Variable not set}
      - KEYCLOAK_ADMIN_LAST_NAME=${KEYCLOAK_ADMIN_LAST_NAME?Variable not set}
      - GRAFANA_ADMIN_EMAIL=${GRAFANA_ADMIN_EMAIL?Variable not set}
      # Credenciales de Postgres para inyecci√≥n de user_auth en Grafana
      - POSTGRES_USER=${POSTGRES_USER?Variable not set}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - GRAFANA_DB_NAME=${GRAFANA_DB_NAME:-grafana}
    entrypoint: /bin/sh
    command:
      - "-c"
      - |
        set -e
        echo "üîß Creando clientes OIDC de Keycloak..."
        echo ""

        # Instalar dependencias necesarias
        apk add --no-cache docker-cli curl bash postgresql-client

        # Esperar a que Keycloak est√© completamente listo (healthcheck + endpoint ready)
        echo "‚è≥ Esperando a que Keycloak est√© listo..."
        MAX_WAIT=120  # Reducido a 2 minutos (suficiente para Keycloak)
        ELAPSED=0
        KEYCLOAK_READY=0

        while [ $$ELAPSED -lt $$MAX_WAIT ]; do
          # Verificar si Keycloak est√° healthy
          KEYCLOAK_STATUS=$$(docker ps --filter "name=keycloak" --format "{{.Status}}" 2>/dev/null || echo "")
          if echo "$$KEYCLOAK_STATUS" | grep -q "healthy"; then
            # Si est√° healthy, intentar verificar el endpoint (m√°ximo 3 intentos)
            for i in 1 2 3; do
              if curl -sf --max-time 5 http://keycloak:8080/health/ready > /dev/null 2>&1; then
                echo "   ‚úÖ Keycloak est√° listo (healthy + ready endpoint)"
                KEYCLOAK_READY=1
                break
              fi
              sleep 2
            done
            
            # Si el endpoint no responde pero est√° healthy, intentar configurar credenciales directamente
            # (a veces el endpoint tarda m√°s pero Keycloak ya acepta conexiones)
            if [ $$KEYCLOAK_READY -eq 0 ]; then
              if docker exec keycloak /opt/keycloak/bin/kcadm.sh config credentials \
                --server http://localhost:8080 \
                --realm master \
                --user "$${KEYCLOAK_ADMIN_USER}" \
                --password "$${KEYCLOAK_ADMIN_PASSWORD}" > /dev/null 2>&1; then
                echo "   ‚úÖ Keycloak est√° listo (healthy, endpoint puede tardar pero acepta conexiones)"
                KEYCLOAK_READY=1
                break
              fi
            fi
            
            if [ $$KEYCLOAK_READY -eq 1 ]; then
              break
            fi
          fi
          
          sleep 5
          ELAPSED=$$((ELAPSED + 5))
          if [ $$((ELAPSED % 20)) -eq 0 ]; then
            echo "   Esperando... ($${ELAPSED}s/$${MAX_WAIT}s)"
          fi
        done

        if [ $$KEYCLOAK_READY -eq 0 ]; then
          echo "   ‚ö†Ô∏è Keycloak no est√° completamente listo despu√©s de $${MAX_WAIT}s"
          echo "   ‚ö†Ô∏è Intentando continuar de todas formas..."
        fi
        echo ""

        echo "üîê Configurando credenciales de administrador..."
        docker exec keycloak /opt/keycloak/bin/kcadm.sh config credentials \
          --server http://localhost:8080 \
          --realm master \
          --user "$${KEYCLOAK_ADMIN_USER}" \
          --password "$${KEYCLOAK_ADMIN_PASSWORD}" > /dev/null 2>&1 && echo "   ‚úÖ Credenciales configuradas" || echo "   ‚ùå Error configurando credenciales"

        # Asegurar email y datos personales del admin (Cr√≠tico para Grafana y consistencia)
        echo "üìß Configurando datos del administrador ($${KEYCLOAK_ADMIN_USER})..."
        ADMIN_ID=$$(docker exec keycloak /opt/keycloak/bin/kcadm.sh get users -r master -q username="$${KEYCLOAK_ADMIN_USER}" --fields id --format csv --noquotes)
        if [ ! -z "$$ADMIN_ID" ]; then
           # Siempre actualizar datos b√°sicos para asegurar consistencia
           docker exec keycloak /opt/keycloak/bin/kcadm.sh update users/$$ADMIN_ID -r master \
             -s email="$${KEYCLOAK_ADMIN_EMAIL}" \
             -s firstName="$${KEYCLOAK_ADMIN_FIRST_NAME}" \
             -s lastName="$${KEYCLOAK_ADMIN_LAST_NAME}" \
             -s emailVerified=true > /dev/null 2>&1
           echo "   ‚úÖ Datos del administrador configurados ($${KEYCLOAK_ADMIN_EMAIL})"
           
           # Esperar a que la BD de Grafana tenga el usuario admin (creado al arranque de Grafana)
           # En clean slate, Grafana puede tardar hasta 90 segundos en inicializar
           echo "   ‚è≥ Esperando a que el usuario admin exista en DB Grafana..."
           MAX_RETRIES=90
           RETRY_COUNT=0
           USER_READY=0
           
           while [ $$RETRY_COUNT -lt $$MAX_RETRIES ]; do
              # Verificar si el usuario 'admin' o con email 'admin@example.com' existe
              if PGPASSWORD="$${POSTGRES_PASSWORD}" psql -h postgres -U "$${POSTGRES_USER}" -d "$${GRAFANA_DB_NAME:-grafana}" -tAc "SELECT 1 FROM \"user\" WHERE email='$$GRAFANA_ADMIN_EMAIL' OR email='admin@example.com' OR login='admin'" 2>/dev/null | grep -q 1; then
                 USER_READY=1
                 echo "      ‚úÖ Usuario detectado despu√©s de $$((RETRY_COUNT * 2))s"
                 break
              fi
              # Log cada 10 segundos
              if [ $$((RETRY_COUNT % 5)) -eq 0 ]; then
                 echo "      Esperando usuario... ($$((RETRY_COUNT * 2))s / 180s)"
              fi
              sleep 2
              RETRY_COUNT=$$((RETRY_COUNT + 1))
           done
           
           if [ $$USER_READY -eq 1 ]; then
               # Inyectar mapeo directamente en la base de datos de Grafana
               PGPASSWORD="$${POSTGRES_PASSWORD}" psql -h postgres -U "$${POSTGRES_USER}" -d "$${GRAFANA_DB_NAME?Variable not set}" -c "
                 INSERT INTO user_auth (user_id, auth_module, auth_id, created, o_auth_access_token, o_auth_refresh_token, o_auth_token_type, o_auth_expiry, o_auth_id_token)
                 SELECT id, 'oauth_generic_oauth', '$$ADMIN_ID', NOW(), '', '', '', null, ''
                 FROM \"user\" 
                 WHERE email='$$GRAFANA_ADMIN_EMAIL' OR email='admin@example.com' OR login='admin'
                 AND NOT EXISTS (SELECT 1 FROM user_auth WHERE auth_id='$$ADMIN_ID');
               " 2>/dev/null && echo "   ‚úÖ Enlace de usuario inyectado en DB Grafana" || echo "   ‚ö†Ô∏è Error inyectando enlace"
           else
               echo "   ‚ö†Ô∏è Timeout esperando usuario admin en Grafana. El enlace manual fall√≥."
           fi

        else
           echo "   ‚ö†Ô∏è No se pudo encontrar al usuario admin para actualizar email"
        fi

        create_or_update_client() {
          CLIENT_ID=$$1
          CLIENT_NAME=$$2
          REDIRECT_URI=$$3
          WEB_ORIGIN=$$4
          CLIENT_SECRET=$$5
          
          echo "   Processing client '$$CLIENT_ID'..."
          
          # Obtener ID si existe
          EXISTING_ID=$$(docker exec keycloak /opt/keycloak/bin/kcadm.sh get clients -r master -q clientId=$$CLIENT_ID --fields id --format csv --noquotes)
          
          if [ ! -z "$$EXISTING_ID" ]; then
             echo "      ‚ö†Ô∏è Client '$$CLIENT_ID' already exists. Recreating to apply latest mappers..."
             docker exec keycloak /opt/keycloak/bin/kcadm.sh delete clients/$$EXISTING_ID -r master > /dev/null 2>&1
          fi
          
          echo "      Creating client '$$CLIENT_ID'..."
          docker exec keycloak /opt/keycloak/bin/kcadm.sh create clients -r master \
            -s clientId=$$CLIENT_ID \
            -s name="$$CLIENT_NAME" \
            -s enabled=true \
            -s clientAuthenticatorType=client-secret \
            -s secret="$$CLIENT_SECRET" \
            -s "redirectUris=[\"$$REDIRECT_URI\"]" \
            -s "webOrigins=[\"$$WEB_ORIGIN\"]" \
            -s standardFlowEnabled=true \
            -s directAccessGrantsEnabled=true \
            -s protocol=openid-connect \
            -s "protocolMappers=[{\"name\":\"email\",\"protocol\":\"openid-connect\",\"protocolMapper\":\"oidc-usermodel-property-mapper\",\"consentRequired\":false,\"config\":{\"user.attribute\":\"email\",\"id.token.claim\":\"true\",\"access.token.claim\":\"true\",\"claim.name\":\"email\",\"jsonType.label\":\"String\"}},{\"name\":\"username\",\"protocol\":\"openid-connect\",\"protocolMapper\":\"oidc-usermodel-property-mapper\",\"consentRequired\":false,\"config\":{\"user.attribute\":\"username\",\"id.token.claim\":\"true\",\"access.token.claim\":\"true\",\"claim.name\":\"preferred_username\",\"jsonType.label\":\"String\"}},{\"name\":\"client roles\",\"protocol\":\"openid-connect\",\"protocolMapper\":\"oidc-usermodel-client-role-mapper\",\"consentRequired\":false,\"config\":{\"multivalued\":\"true\",\"user.attribute\":\"foo\",\"id.token.claim\":\"true\",\"access.token.claim\":\"true\",\"claim.name\":\"resource_access.$${CLIENT_ID}.roles\",\"jsonType.label\":\"String\"}},{\"name\":\"audience\",\"protocol\":\"openid-connect\",\"protocolMapper\":\"oidc-audience-mapper\",\"consentRequired\":false,\"config\":{\"included.client.audience\":\"$$CLIENT_ID\",\"id.token.claim\":\"true\",\"access.token.claim\":\"true\"}}]" \
            > /dev/null 2>&1 && echo "      ‚úÖ Client '$$CLIENT_ID' created/updated" || echo "      ‚ùå Error processing '$$CLIENT_ID'"
          
        }

        # Crear o actualizar clientes
        create_or_update_client "grafana" "grafana" "$${GRAFANA_URL_PUBLIC}/login/generic_oauth" "$${GRAFANA_URL_PUBLIC}" "$${GRAFANA_OAUTH_CLIENT_SECRET}"
        create_or_update_client "n8n" "n8n" "$${N8N_URL_PUBLIC}/rest/oauth2-credential/callback" "$${N8N_URL_PUBLIC}" "$${N8N_OIDC_CLIENT_SECRET}"
        create_or_update_client "open-webui" "open-webui" "$${OPEN_WEBUI_URL_PUBLIC}/oauth/oidc/callback" "$${OPEN_WEBUI_URL_PUBLIC}" "$${OPEN_WEBUI_OAUTH_CLIENT_SECRET}"
        create_or_update_client "jenkins" "jenkins" "$${JENKINS_URL_PUBLIC}/securityRealm/finishLogin" "$${JENKINS_URL_PUBLIC}" "$${JENKINS_OIDC_CLIENT_SECRET}"

        echo ""
        echo "‚úÖ Clientes OIDC procesados"
    depends_on:
      keycloak:
        condition: service_healthy
    restart: "no" # Solo se ejecuta una vez
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # ModSecurity - Firewall de aplicaciones web
  modsecurity:
    image: owasp/modsecurity-crs:nginx
    container_name: modsecurity
    profiles: [ "security" ]
    volumes:
      - ./modsecurity/modsecurity.conf:/etc/nginx/modsecurity/modsecurity.conf:ro
      - ./modsecurity/rules:/etc/nginx/modsecurity/rules:ro
      - modsecurity_data:/var/log/modsecurity
    networks:
      - security-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 256M

  # =============================================================================
  # SERVICIOS DE AUTOMATIZACI√ìN Y CI/CD
  # =============================================================================
  # Servicios para automatizar tareas y desarrollo

  # Watchtower - Actualizaciones autom√°ticas de contenedores
  watchtower:
    image: containrrr/watchtower:latest
    container_name: watchtower
    profiles: [ "automation" ]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - WATCHTOWER_CLEANUP=${WATCHTOWER_CLEANUP:-true}
      - WATCHTOWER_SCHEDULE=${WATCHTOWER_SCHEDULE:-0 0 2 * * *}
      - WATCHTOWER_NOTIFICATIONS=${WATCHTOWER_NOTIFICATIONS?Variable not set}
      - WATCHTOWER_EMAIL_FROM=${WATCHTOWER_EMAIL_FROM?Variable not set}
      - WATCHTOWER_NOTIFICATION_EMAIL_FROM=${WATCHTOWER_EMAIL_FROM?Variable not set}
      - WATCHTOWER_EMAIL_TO=${WATCHTOWER_EMAIL_TO?Variable not set}
      - WATCHTOWER_EMAIL_SERVER=${WATCHTOWER_EMAIL_SERVER?Variable not set}
      - WATCHTOWER_EMAIL_SERVER_PORT=${WATCHTOWER_EMAIL_SERVER_PORT?Variable not set}
      - WATCHTOWER_EMAIL_SERVER_USER=${WATCHTOWER_EMAIL_SERVER_USER?Variable not set}
      - WATCHTOWER_EMAIL_SERVER_PASSWORD=${WATCHTOWER_EMAIL_SERVER_PASSWORD?Variable not set}
    networks:
      - monitoring-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Jenkins - CI/CD Pipeline
  jenkins:
    build:
      context: ./config/jenkins
      dockerfile: Dockerfile
    container_name: jenkins
    profiles: [ "ci-cd", "gen-ai" ] # Include gen-ai to resolve keycloak dependency
    ports:
      - "${PORT_JENKINS_HOST:-8081}:8082"
      - "${PORT_JENKINS_AGENT_HOST:-50000}:${PORT_JENKINS_AGENT_CONTAINER:-50000}"
    volumes:
      - jenkins_data:/var/jenkins_home
      - ./config/jenkins/init.groovy.d:/var/jenkins_home/init.groovy.d:ro
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - JAVA_OPTS=-Djenkins.install.runSetupWizard=false
      - JENKINS_OPTS=--httpPort=8082
      # Variables para script de inicializaci√≥n OIDC
      - JENKINS_URL_PUBLIC=${JENKINS_URL_PUBLIC:-http://localhost:8081}
      - JENKINS_ADMIN_USER=${JENKINS_ADMIN_USER?Variable not set}
      - JENKINS_ADMIN_PASSWORD=${JENKINS_ADMIN_PASSWORD?Variable not set}
      - JENKINS_OIDC_CLIENT_ID=${JENKINS_OIDC_CLIENT_ID:-jenkins}
      - JENKINS_OIDC_CLIENT_SECRET=${KEYCLOAK_CLIENT_SECRET_JENKINS?Variable not set}
      - JENKINS_OIDC_SCOPES=${JENKINS_OIDC_SCOPES:-openid email profile}
      - KEYCLOAK_URL_PUBLIC=${KEYCLOAK_URL_PUBLIC:-http://localhost:8080}
      - KEYCLOAK_REALM=${KEYCLOAK_REALM:-master}
    depends_on:
      keycloak:
        condition: service_healthy
      keycloak-init:
        condition: service_completed_successfully
    networks:
      - backend-network
      - genai-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8082/login" ]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G

  # Servicio de testing autom√°tico
  test-runner:
    image: alpine:latest
    container_name: test-runner
    profiles: [ "testing" ]
    volumes:
      - .:/workspace
    command: |
      sh -c "
      apk add --no-cache curl
      while true; do
        echo 'Testing services...'
        curl -f http://open-webui:8080/healthz || echo 'Open WebUI down'
        curl -f http://n8n:5678/healthz || echo 'n8n down'
        curl -f http://ollama:11434/api/tags || echo 'Ollama down'
        curl -f http://qdrant:6333/health || echo 'Qdrant down'
        echo 'Tests completed at $$(date)'
        sleep 300
      done
      "
    networks:
      - genai-network
    depends_on:
      - open-webui
      - n8n
      - ollama
      - qdrant
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Servicio de sincronizaci√≥n de datos
  sync:
    image: alpine:latest
    container_name: sync
    profiles: [ "automation" ]
    volumes:
      - shared_data:/data
      - backup_data:/backup
    command: |
      sh -c "
      apk add --no-cache rsync
      while true; do
        echo 'Syncing data...'
        rsync -av /data/ /backup/sync/
        echo 'Sync completed at $$(date)'
        sleep 3600
      done
      "
    networks:
      - backend-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M

  # Servicio de debugging avanzado
  debug-tools:
    image: alpine:latest
    container_name: debug-tools
    profiles: [ "debug" ]
    volumes:
      - .:/workspace
      - /var/run/docker.sock:/var/run/docker.sock
    working_dir: /workspace
    command: |
      sh -c "
      apk add --no-cache curl jq htop vim nano git docker-cli
      echo 'Debug tools ready. Available commands:'
      echo '- curl: HTTP requests'
      echo '- jq: JSON processing'
      echo '- htop: Process monitoring'
      echo '- vim/nano: Text editing'
      echo '- git: Version control'
      echo '- docker: Container management'
      tail -f /dev/null
      "
    networks:
      - genai-network
      - monitoring-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 128M
