<!--
üåê Idioma: Espa√±ol | [English](README.md)
-->

> **Esta documentaci√≥n est√° en espa√±ol. La versi√≥n principal en ingl√©s est√° en [README.md](README.md).**

# My Self-Hosted AI Kit (Kit de IA Auto-hospedado)

Un stack completo de herramientas de Inteligencia Artificial auto-hospedadas usando Docker Compose. Este proyecto incluye Ollama para modelos de lenguaje local, n8n para automatizaci√≥n, Open WebUI para interfaz de chat, y m√°s.

## üöÄ ¬øQu√© incluye este stack?

### Servicios principales:
- **Ollama**: Servidor de modelos de lenguaje local (LLMs)
- **Open WebUI** (v0.7.2): Interfaz web moderna para chat con IA
- **n8n** (v1.122.5): Plataforma de automatizaci√≥n de flujos de trabajo
- **PostgreSQL**: Base de datos para n8n y Keycloak
- **Qdrant**: Base de datos vectorial para embeddings
- **Redis**: Cach√© y gesti√≥n de sesiones
- **pgvector**: Extensi√≥n de PostgreSQL para vectores

> **Nota**: Las versiones de los servicios est√°n fijadas para estabilidad. Ver `docker-compose.yml` para versiones exactas.

### Servicios opcionales:
- **Automatic Backup Runner**: Respaldo diario automatizado y auto-contenido (perfil `monitoring`)
- **Herramientas de desarrollo**: Contenedor con utilidades (perfil `dev`)

### Modelos de IA incluidos:
- llama3.2 (3.2B par√°metros - m√°s r√°pido, menos preciso)
- llama3.3 (70.6B par√°metros - m√°s lento, m√°s preciso)
- all-minilm (modelo de embeddings, se actualiza autom√°ticamente)
- deepseek-r1:14b (modelo especializado, optimizado para 16GB VRAM)
- nomic-embed-text (embeddings de texto, se actualiza autom√°ticamente)

## üìã Prerrequisitos

### Software necesario:
- **Docker Engine** (no Docker Desktop)
- **Docker Compose**
- **Git** (para clonar el repositorio)
- **jq** (para procesar JSON en scripts de pruebas)
- **curl** (para pruebas de API)

**Instalaci√≥n R√°pida (Ubuntu/Debian):**
```bash
# 1. Instalar Docker
curl -fsSL https://get.docker.com | sh
sudo usermod -aG docker $USER
# (Cierra sesi√≥n y vuelve a entrar para aplicar cambios)

# 2. Instalar Herramientas (Git, jq, curl)
sudo apt-get update && sudo apt-get install -y git jq curl
```

### Hardware recomendado:
- **RAM**: M√≠nimo 8GB, recomendado 16GB+
- **GPU**: NVIDIA con drivers propietarios (recomendado: GPU con 8GB+ VRAM)
- **CPU**: M√≠nimo 4 cores, recomendado 8+ cores
- **Almacenamiento**: Al menos 50GB libres (los modelos de IA son grandes)

## üõ†Ô∏è Instalaci√≥n

### 1. Clonar el repositorio
```bash
git clone <tu-repositorio>
cd my-selfhosted-ai-kit
```

### 2. Configurar variables de entorno
Crea un archivo `.env` en la ra√≠z del proyecto:
```bash
cp .env.example .env
# Edita el archivo con tu editor favorito
nano .env
```

**CR√çTICO**: Aseg√∫rate de configurar tu informaci√≥n en la secci√≥n `OIDC User Emulation`. Estos valores se usar√°n para generar autom√°ticamente tu perfil local en Open WebUI:
- `OPEN_WEBUI_OIDC_USER_EMAIL`: Tu correo de admin
- `OPEN_WEBUI_OIDC_USER_NAME`: Tu nombre completo

Consulta la [**Gu√≠a de Configuraci√≥n**](docs/CONFIGURATION.md) para m√°s detalles sobre la generaci√≥n din√°mica.

# Configuraci√≥n de n8n
N8N_ENCRYPTION_KEY=tu_clave_de_encriptacion_32_caracteres
N8N_USER_MANAGEMENT_JWT_SECRET=tu_jwt_secret_seguro
```

### 3. Configurar GPU (opcional)
Si tienes GPU NVIDIA y quieres aceleraci√≥n:

```bash
# Instalar nvidia-container-toolkit
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker

# Verificar que funciona
sudo docker run --rm --gpus all nvidia/cuda:12.0.0-base-ubuntu22.04 nvidia-smi
```

## üöÄ Uso

### Recomendado: Usar el Script Stack Manager

El proyecto incluye un script mejorado `stack-manager.sh` con **resoluci√≥n autom√°tica de dependencias**. Cuando inicias un perfil, autom√°ticamente incluye todas las dependencias requeridas:

```bash
# Iniciar Open WebUI con todas sus dependencias (Keycloak, Redis, Ollama)
./scripts/stack-manager.sh start chat-ai
# Auto-incluye: security infrastructure gpu-nvidia

# Iniciar automatizaci√≥n con autenticaci√≥n
./scripts/stack-manager.sh start automation
# Auto-incluye: security

# Iniciar el preset por defecto (recomendado para producci√≥n)
./scripts/stack-manager.sh start

# Detener todos los servicios
./scripts/stack-manager.sh stop

# Ver presets y perfiles disponibles
./scripts/stack-manager.sh list

# Modo debug (ver resoluci√≥n de perfiles)
DEBUG_PROFILES=true ./scripts/stack-manager.sh start chat-ai
```

### Perfiles disponibles

El stack incluye diferentes perfiles para optimizar seg√∫n tus necesidades:

#### Perfil b√°sico (CPU):
```bash
docker compose --profile cpu up -d
```

#### Perfil GPU NVIDIA (recomendado si tienes GPU NVIDIA):
```bash
docker compose --profile gpu-nvidia up -d
```

#### Perfil GPU AMD:
```bash
docker compose --profile gpu-amd up -d
```

#### Perfil de desarrollo:
```bash
docker compose --profile dev up -d
```

#### Perfil de monitoreo y respaldos:
```bash
docker compose --profile monitoring up -d
```

#### Perfil de infraestructura (Redis, HAProxy):
```bash
docker compose --profile infrastructure up -d
```

#### Perfil de seguridad (Keycloak, ModSecurity):
```bash
docker compose --profile security up -d
```

#### Perfil de automatizaci√≥n (Watchtower, Sync):
```bash
docker compose --profile automation up -d
```

#### Perfil de CI/CD (Jenkins):
```bash
docker compose --profile ci-cd up -d
```

#### Perfil de testing:
```bash
docker compose --profile testing up -d
```

#### Perfil de debugging:
```bash
docker compose --profile debug up -d
```

#### Combinar m√∫ltiples perfiles:
```bash
# Producci√≥n completa con GPU, monitoreo e infraestructura
docker compose --profile gpu-nvidia --profile monitoring --profile infrastructure up -d

# Desarrollo con herramientas y testing
docker compose --profile cpu --profile dev --profile testing up -d

# Stack completo (¬°cuidado con el uso de recursos!)
docker compose --profile gpu-nvidia --profile monitoring --profile infrastructure --profile security --profile automation up -d
```

## üß© ¬øQu√© hace cada perfil y c√≥mo usarlos?

| Perfil           | ¬øQu√© incluye?                                                                 | ¬øCu√°ndo usarlo?                                                                                   | ¬øSe recomienda combinar?         |
|------------------|-------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|----------------------------------|
| **cpu**          | Ollama (CPU)                                                                  | No tienes GPU o quieres ahorrar recursos.                                                         | S√≠, con otros servicios.         |
| **gpu-nvidia**   | Ollama (GPU NVIDIA), model puller, nvidia-exporter                            | Tienes GPU NVIDIA y quieres m√°ximo rendimiento en IA.                                             | S√≠, con otros servicios.         |
| **gpu-amd**      | Ollama (GPU AMD)                                                              | Tienes GPU AMD compatible.                                                                        | S√≠, con otros servicios.         |
| **chat-ai**      | Open WebUI                                                                    | Interfaz de chat IA con autenticaci√≥n Keycloak.                                                   | Auto-incluye: security, infrastructure, gpu-nvidia |
| **monitoring**   | Prometheus, Grafana, AlertManager, backup, exporters (node, cAdvisor, postgres, redis, ollama, n8n, openwebui) | Quieres monitoreo, dashboards y respaldos autom√°ticos.                                            | Auto-incluye: security, infrastructure |
| **infrastructure**| Redis, HAProxy                                                               | Necesitas cache o balanceo de carga.                                                              | S√≠, con cualquier perfil.        |
| **security**     | Keycloak, keycloak-init, ModSecurity (WAF)                                    | Quieres autenticaci√≥n centralizada y firewall de aplicaciones web.                                | S√≠, con cualquier perfil.        |
| **automation**   | n8n, Watchtower (auto-actualizaci√≥n), Sync                                    | Quieres automatizaci√≥n de workflows y actualizaciones de contenedores.                            | Auto-incluye: security           |
| **ci-cd**        | Jenkins (puerto 8081‚Üí8082)                                                    | Necesitas pipelines de integraci√≥n y despliegue continuo.                                         | Auto-incluye: security           |
| **gen-ai**       | Keycloak, Jenkins                                                             | Servicios de IA combinados con autenticaci√≥n.                                                     | Alias para security + ci-cd      |
| **testing**      | Test Runner                                                                   | Quieres monitoreo autom√°tico de salud de servicios.                                               | S√≠, con cualquier perfil.        |
| **debug**        | Debug Tools                                                                   | Necesitas herramientas avanzadas de debugging.                                                    | S√≠, con cualquier perfil.        |
| **dev**          | Herramientas de desarrollo (curl, jq, etc.)                                   | Est√°s desarrollando o depurando el stack.                                                         | S√≠, con cualquier perfil.        |

---

### üîë ¬øDebo levantar m√°s de un perfil a la vez?

**¬°S√≠!**  
Cada perfil es modular y **debes combinarlos** seg√∫n tus necesidades.  
Por ejemplo, si solo levantas `security`, tendr√°s Keycloak y ModSecurity, pero **no tendr√°s IA, ni monitoreo, ni automatizaci√≥n**.

#### Ejemplos de combinaciones recomendadas:

- **Desarrollo b√°sico (sin GPU):**
  ```bash
  docker compose --profile cpu --profile dev up -d
  ```
- **IA con GPU y monitoreo:**
  ```bash
  docker compose --profile gpu-nvidia --profile monitoring up -d
  ```
- **Producci√≥n completa (IA, monitoreo, seguridad, infraestructura):**
  ```bash
  docker compose --profile gpu-nvidia --profile monitoring --profile infrastructure --profile security up -d
  ```
- **Solo autenticaci√≥n y seguridad:**
  ```bash
  docker compose --profile security up -d
  ```

### üó∫Ô∏è Diagrama visual de perfiles y dependencias

```mermaid
flowchart TD
    subgraph IA
        CPU["Perfil cpu\nOllama (CPU)"]
        NVIDIA["Perfil gpu-nvidia\nOllama (GPU NVIDIA)"]
        AMD["Perfil gpu-amd\nOllama (GPU AMD)"]
    end
    subgraph Servicios
        MON["monitoring\nPrometheus, Grafana, AlertManager, backup"]
        INFRA["infrastructure\nRedis, HAProxy"]
        SEC["security\nKeycloak, ModSecurity"]
        AUTO["automation\nWatchtower, Sync"]
        CICD["ci-cd\nJenkins"]
        TEST["testing\nTest Runner"]
        DEBUG["debug\nDebug Tools"]
        DEV["dev\nHerramientas de desarrollo"]
    end
    CPU---MON
    NVIDIA---MON
    AMD---MON
    CPU---INFRA
    NVIDIA---INFRA
    AMD---INFRA
    CPU---SEC
    NVIDIA---SEC
    AMD---SEC
    CPU---AUTO
    NVIDIA---AUTO
    AMD---AUTO
    CPU---CICD
    NVIDIA---CICD
    AMD---CICD
    CPU---TEST
    NVIDIA---TEST
    AMD---TEST
    CPU---DEBUG
    NVIDIA---DEBUG
    AMD---DEBUG
    CPU---DEV
    NVIDIA---DEV
    AMD---DEV
    classDef ia fill:#e0f7fa,stroke:#00796b,stroke-width:2px;
    classDef servicios fill:#fff3e0,stroke:#e65100,stroke-width:2px;
    class IA,Servicios ia,servicios;
```

### üñºÔ∏è Versi√≥n en imagen

![Diagrama de perfiles y dependencias](diagrams_png/perfiles.png)

### üóíÔ∏è Leyenda de colores del diagrama

- **L√≠neas azules**: Conexiones desde el perfil `cpu`
- **L√≠neas verdes**: Conexiones desde el perfil `gpu-nvidia`
- **L√≠neas naranjas**: Conexiones desde el perfil `gpu-amd`
- **L√≠neas moradas**: Servicios de monitoreo (`monitoring`)
- **L√≠neas rojas**: Servicios de seguridad (`security`)
- **L√≠neas marrones**: Servicios de infraestructura (`infrastructure`)
- **L√≠neas celestes**: Servicios de automatizaci√≥n (`automation`)
- **L√≠neas gris oscuro**: Servicios de CI/CD (`ci-cd`)
- **L√≠neas verde lima**: Servicios de testing (`testing`)
- **L√≠neas rosas**: Servicios de debugging (`debug`)
- **L√≠neas amarillas**: Herramientas de desarrollo (`dev`)

---

### Ver logs en tiempo real:
```bash
docker compose logs -f
```

### Gestionar el stack con el script maestro:
```bash
# Levantar servicios (por defecto: gpu-nvidia + monitoring + infrastructure + security)
./scripts/stack-manager.sh start

# Levantar con perfiles espec√≠ficos
./scripts/stack-manager.sh start gpu-nvidia monitoring

# Ver estado
./scripts/stack-manager.sh status

# Ver ayuda
./scripts/stack-manager.sh help
```

### Monitorear descarga de modelos:
```bash
./scripts/stack-manager.sh monitor
```

### Detener todos los servicios:
```bash
docker compose down
# O usando stack-manager:
./scripts/stack-manager.sh stop
```

## üåê Acceso a las aplicaciones

Una vez que los servicios est√©n corriendo, puedes acceder a:

| Servicio | Via HAProxy (recomendado) | Puerto Directo | Descripci√≥n |
|----------|---------------------------|----------------|-------------|
| **Open WebUI** | http://localhost/chat | http://localhost:3000 | Interfaz web para chat con IA |
| **n8n** | ‚è≥ Pendiente | http://localhost:5678 | Automatizaci√≥n de flujos de trabajo |
| **Grafana** | http://localhost/grafana | http://localhost:3001 | Dashboards de monitoreo (Auth via Keycloak) |
| **Prometheus** | http://localhost/prometheus | http://localhost:9090 | M√©tricas del sistema |
| **AlertManager** | http://localhost/alertmanager | http://localhost:9093 | Gesti√≥n de alertas |
| **Keycloak** | ‚è≥ Pendiente | http://localhost:8080 | Autenticaci√≥n centralizada |
| **Jenkins** | - | http://localhost:8081 | CI/CD Pipeline |
| **Qdrant** | - | http://localhost:6333 | Base de datos vectorial |
| **pgvector** | - | localhost:5433 | PostgreSQL con vectores |
| **cAdvisor** | - | http://localhost:8082 | M√©tricas de contenedores |
| **Node Exporter** | - | http://localhost:9100 | M√©tricas del host |
| **Redis** | - | localhost:6379 | Cache y sesiones |

<!-- TODO: Configurar paths de HAProxy para n8n (/n8n) y Keycloak (/keycloak) en haproxy/haproxy.cfg -->

> **Nota**: HAProxy (puerto 80) proporciona balanceo de carga, rate limiting y acceso unificado. Los puertos directos omiten estas caracter√≠sticas pero funcionan para desarrollo/debugging. Los elementos marcados "‚è≥ Pendiente" requieren configuraci√≥n de HAProxy.

## üìö Gu√≠a de uso por servicio

### Open WebUI
- **Prop√≥sito**: Interfaz web moderna para interactuar con modelos de IA
- **Primer uso**: 
  1. Ve a http://localhost:3000
  2. Crea una cuenta o inicia sesi√≥n
  3. Selecciona un modelo de la lista
  4. ¬°Comienza a chatear!

### n8n
- **Prop√≥sito**: Automatizar tareas y flujos de trabajo
- **Primer uso**:
  1. Ve a http://localhost:5678
  2. Completa la configuraci√≥n inicial
  3. Crea tu primer workflow
  4. Conecta con Ollama para usar IA en tus automatizaciones

### Ollama
- **Prop√≥sito**: Servidor de modelos de lenguaje local
- **API**: http://localhost:11434
- **Modelos disponibles**: Ejecuta `docker exec ollama ollama list`
- **Optimizado para**: GPUs NVIDIA con 8GB+ VRAM

## üîß Comandos √∫tiles

### Usando el gestor del stack (recomendado):
```bash
# Levantar servicios con preset por defecto
./scripts/stack-manager.sh start

# Ver estado de servicios
./scripts/stack-manager.sh status

# Ver logs
./scripts/stack-manager.sh logs [nombre-servicio]

# Reiniciar servicios
./scripts/stack-manager.sh restart [perfiles...]

# Validar configuraci√≥n
./scripts/stack-manager.sh validate

# Ejecutar validaci√≥n autom√°tica completa
./scripts/stack-manager.sh auto-validate

# Probar cambios recientes
./scripts/stack-manager.sh test

# Inicializar vol√∫menes (solo primera vez)
./scripts/stack-manager.sh init-volumes

# Monitorear descarga de modelos
./scripts/stack-manager.sh monitor
```

### Comandos directos de Docker Compose:
```bash
# Ver estado de servicios
docker compose ps

# Ver logs de un servicio espec√≠fico
docker compose logs -f [nombre-servicio]
# Ejemplo: docker compose logs -f ollama

# Reiniciar un servicio
docker compose restart [nombre-servicio]

# Ver uso de recursos
docker stats

# Limpiar espacio (eliminar im√°genes no usadas)
docker system prune -a
```

### üîê Gesti√≥n de Keycloak:
```bash
# Configurar roles (salta autom√°ticamente los existentes)
./scripts/auth-manager.sh --setup-roles

# Crear usuario administrador
./scripts/auth-manager.sh --create-admin

# Corregir clientes OIDC
./scripts/auth-manager.sh --fix-clients

# Ver estado
./scripts/auth-manager.sh --status

# Ver ayuda
./scripts/auth-manager.sh --help
```

## üìÅ Estructura de vol√∫menes

Todos los datos se almacenan en vol√∫menes persistentes de Docker:

- `n8n_storage`: Datos de n8n (workflows, credenciales)
- `ollama_storage`: Modelos de IA descargados
- `postgres_storage`: Base de datos PostgreSQL
- `qdrant_storage`: Base de datos vectorial
- `open_webui_storage`: Datos de Open WebUI
- `backup_data`: Respaldo autom√°tico de datos
- `prometheus_data`: M√©tricas de monitoreo (opcional)
- `grafana_data`: Dashboards de Grafana (opcional)

## üîß Servicios adicionales

### Infraestructura (perfil `infrastructure`)
- **Redis**: Cache en memoria para mejorar rendimiento
- **HAProxy**: Load balancer con caracter√≠sticas avanzadas:
  - Health checks avanzados (inter 3s, fall 3, rise 2)
  - Rate limiting (100 req/10s por IP) - Protecci√≥n DDoS
  - Routing basado en paths (backends espec√≠ficos por servicio)
  - Timeouts optimizados
  - Logging - Estad√≠sticas y logging mejorados
  - **Cola de Peticiones GPU**: Previene OOM poniendo en cola las inferencias (`maxconn 1`)
  - Opciones de balanceo mejoradas

### Monitoreo (perfil `monitoring`)
- **Prometheus**: Recolector de m√©tricas
- **Grafana**: Dashboards pre-configurados:
  - **Ollama AI Models Dashboard**: Monitoreo espec√≠fico de modelos de IA
  - **System Overview**: Vista general del sistema completo
- **AlertManager**: Gesti√≥n de alertas
- **Node Exporter**: M√©tricas del host
- **cAdvisor**: M√©tricas de contenedores
- **PostgreSQL Exporter**: M√©tricas de PostgreSQL

### Seguridad (perfil `security`)
- **Keycloak**: Autenticaci√≥n y autorizaci√≥n centralizada
- **ModSecurity**: Firewall de aplicaciones web (WAF)

### Automatizaci√≥n (perfil `automation`)
- **Watchtower**: Actualizaciones autom√°ticas de contenedores
- **Sync**: Sincronizaci√≥n autom√°tica de datos

### CI/CD (perfil `ci-cd`)
- **Jenkins**: Pipeline de integraci√≥n y despliegue continuo

### Testing (perfil `testing`)
- **Test Runner**: Monitoreo autom√°tico de salud de servicios

### Debug (perfil `debug`)
- **Debug Tools**: Herramientas avanzadas de debugging

## üöÄ Optimizaci√≥n para tu hardware

Ejemplo de especificaciones probadas:
- **CPU**: AMD Ryzen 7 7700 (8 cores, 16 threads) o equivalente
- **RAM**: 32GB+ DDR5 (probado con 96GB)
- **GPU**: NVIDIA RTX serie 40/50 con 16GB VRAM

### Configuraciones recomendadas:

#### Para m√°ximo rendimiento:
```bash
# Stack completo con GPU
docker compose --profile gpu-nvidia --profile monitoring --profile infrastructure up -d
```

#### Para desarrollo:
```bash
# Stack de desarrollo con herramientas
docker compose --profile cpu --profile dev --profile testing up -d
```

#### Para producci√≥n:
```bash
# Stack de producci√≥n con seguridad
docker compose --profile gpu-nvidia --profile monitoring --profile infrastructure --profile security up -d
```

## üîí Seguridad

### Recomendaciones:
1. **Cambia las contrase√±as por defecto** en el archivo `.env`
2. **No expongas los puertos** a Internet sin configuraci√≥n adicional
3. **Usa HTTPS** en producci√≥n
4. **Mant√©n actualizados** los contenedores

### Variables sensibles:
- `POSTGRES_PASSWORD`: Contrase√±a de la base de datos
- `N8N_ENCRYPTION_KEY`: Clave para encriptar datos de n8n
- `N8N_USER_MANAGEMENT_JWT_SECRET`: Clave para tokens JWT

## üêõ Soluci√≥n de problemas

### Problema: "Cannot connect to Docker daemon"
```bash
sudo systemctl start docker
sudo usermod -aG docker $USER
# Cierra sesi√≥n y vuelve a entrar
```

### Problema: GPU no funciona
```bash
# Verificar drivers NVIDIA
nvidia-smi

# Verificar runtime de Docker
sudo docker run --rm --gpus all nvidia/cuda:12.0.0-base-ubuntu22.04 nvidia-smi
```

### Problema: Modelos no se descargan
```bash
# Ver logs del contenedor de descarga
docker logs ollama-pull-llama

# Descargar manualmente
docker exec -it ollama ollama pull llama3.2
```

### Problema: Puerto ya en uso
```bash
# Ver qu√© usa el puerto
sudo netstat -tulpn | grep :3000

# Cambiar puerto en docker-compose.yml
```

### Problema: Keycloak Login Fallido ("Failed to get token")
Esto usualmente significa que los secretos del cliente Keycloak no coinciden.
```bash
# Forzar actualizaci√≥n de secretos de clientes (keycloak-init se ejecuta autom√°ticamente al iniciar)
# Si necesitas ejecutarlo manualmente:
docker compose --profile security up -d keycloak-init

# O simplemente reinicia el perfil security (keycloak-init se ejecutar√° autom√°ticamente)
./scripts/stack-manager.sh restart security
```

### Problema: Grafana Login Fallido ("InternalError")
Esto usualmente ocurre si el usuario de Keycloak no tiene direcci√≥n de email.
```bash
# Establecer email para el usuario admin
docker exec keycloak /opt/keycloak/bin/kcadm.sh update users/$(docker exec keycloak /opt/keycloak/bin/kcadm.sh get users -r master -q username=admin --fields id --format csv --noquotes) -r master -s email=admin@example.com -s emailVerified=true
```

### Problema: Grafana Login Fallido ("User sync failed")
Esto ocurre si Grafana no puede mapear el usuario de Keycloak a un usuario local existente.
**Aseg√∫rate de que el email del admin de Grafana coincida con el email del admin de Keycloak.**
1. Verifica el email en Keycloak (ej: `admin@example.com`).
2. Actualiza `.env` para que coincida:
   ```bash
   GRAFANA_ADMIN_EMAIL=admin@example.com
   ```
3. Reinicia Grafana:
   ```bash
   ./scripts/stack-manager.sh start
   ```

### Problema: Logs muy grandes
```bash
# Los logs est√°n configurados para rotar autom√°ticamente
# Si necesitas limpiar manualmente:
docker system prune -f
```

## üìà Monitoreo y mantenimiento

### Verificar salud de los servicios:
```bash
docker compose ps
```

### Backup de datos:
```bash
# Crear backup (recomendado)
./scripts/backup-manager.sh backup

# Crear backup completo con verificaci√≥n
./scripts/backup-manager.sh backup --full --verify

# Listar backups disponibles
./scripts/backup-manager.sh list

# Restaurar desde backup
./scripts/backup-manager.sh restore <timestamp>

# Ver ayuda
./scripts/backup-manager.sh help
```

### Actualizar servicios:
```bash
docker compose pull
docker compose up -d
```

### Monitorear uso de recursos:
```bash
# Ver uso en tiempo real
docker stats

# Ver logs de todos los servicios
docker compose logs -f
```

## üõ†Ô∏è Servicios opcionales

### Perfil de Monitoreo (`monitoring`)
El perfil `monitoring` agrega un stack completo de monitoreo y observabilidad:

#### Prometheus - Recolector de m√©tricas
- **URL**: http://localhost/prometheus (via HAProxy) o http://localhost:9090 (directo)
- **Funci√≥n**: Recolecta m√©tricas de todos los servicios del stack
- **M√©tricas incluidas**: CPU, memoria, estado de salud, logs de errores

#### Grafana - Dashboards y visualizaci√≥n
- **URL**: http://localhost/grafana (via HAProxy) o http://localhost:3001 (directo)
- **Autenticaci√≥n**: Via Keycloak OAuth - clic en "Sign in with Keycloak"
- **Nota**: El login local est√° deshabilitado. Usa tus credenciales de Keycloak.
- **Funci√≥n**: Dashboards visuales para monitorear el rendimiento
- **Dashboards incluidos**: M√©tricas de servicios, uso de recursos, estado de salud

#### AlertManager - Gesti√≥n de alertas
- **URL**: http://localhost/alertmanager (via HAProxy) o http://localhost:9093 (directo)
- **Funci√≥n**: Gestiona alertas cuando los servicios tienen problemas
- **Alertas configuradas**: Servicios ca√≠dos, alto uso de recursos, errores cr√≠ticos

#### Backup autom√°tico
- **Funci√≥n**: Respalda datos diariamente
- **Ubicaci√≥n**: Volumen `backup_data`
- **Frecuencia**: Cada 24 horas

### Herramientas de desarrollo
- **Perfil**: `dev`
- **Funci√≥n**: Contenedor con curl, jq y otras utilidades
- **Uso**: Para debugging y desarrollo

### C√≥mo usar el monitoreo:

```bash
# Levantar stack completo con monitoreo
docker compose --profile gpu-nvidia --profile monitoring up -d

# Acceder a Grafana
# 1. Ve a http://localhost/grafana (o http://localhost:3001 directo)
# 2. Clic en "Sign in with Keycloak" y usa tus credenciales de Keycloak
# 3. Explora los dashboards disponibles

# Acceder a Prometheus
# 1. Ve a http://localhost/prometheus (o http://localhost:9090 directo)
# 2. Ve a Status > Targets para ver servicios monitoreados
# 3. Usa la pesta√±a Graph para consultar m√©tricas

# Ver alertas
# 1. Ve a http://localhost/alertmanager (o http://localhost:9093 directo)
# 2. Revisa alertas activas y configuraci√≥n
```

## ü§ù Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la Licencia Apache 2.0. Ver el archivo `LICENSE` para m√°s detalles.

## üÜò Soporte

Si tienes problemas:
1. Revisa la secci√≥n de soluci√≥n de problemas
2. Consulta [docs/INDEX.md](docs/INDEX.md) para gu√≠a de documentaci√≥n
3. Busca en los issues del repositorio
4. Crea un nuevo issue con detalles del problema

---

## üìö Documentaci√≥n Adicional

Para m√°s informaci√≥n, consulta:
- **[docs/INDEX.md](docs/INDEX.md)** - Gu√≠a de lectura de toda la documentaci√≥n
- **[PROJECT_STATUS.md](docs/PROJECT_STATUS.md)** - ‚≠ê **NUEVO** - Estado del proyecto y tareas pendientes
- **[ROADMAP.md](docs/ROADMAP.md)** - ‚≠ê **NUEVO** - Hoja de ruta y plan de acci√≥n detallado

---

## üìä Ejemplos visuales de stacks t√≠picos

A continuaci√≥n se muestran ejemplos visuales de combinaciones de perfiles para distintos escenarios de uso. Los diagramas fuente (.mmd) est√°n en la carpeta `diagrams_mmd/` y los PNG en `diagrams_png/`.

### Stack m√≠nimo para desarrollo
![Stack m√≠nimo para desarrollo](diagrams_png/dev_stack_minimal.png)
- Solo los servicios esenciales para desarrollo local sin GPU.

### Stack de producci√≥n completo
![Stack de producci√≥n completo](diagrams_png/prod_stack_full.png)
- Incluye IA con GPU, monitoreo, seguridad e infraestructura.

### Solo autenticaci√≥n y seguridad
![Solo autenticaci√≥n y seguridad](diagrams_png/security_stack.png)
- Para cuando solo quieres levantar Keycloak y ModSecurity.

### IA con GPU y monitoreo
![IA con GPU y monitoreo](diagrams_png/gpu_monitoring_stack.png)
- Para pruebas de rendimiento y observabilidad.

### Stack de automatizaci√≥n y CI/CD
![Stack de automatizaci√≥n y CI/CD](diagrams_png/automation_cicd_stack.png)
- Para flujos autom√°ticos y pipelines de integraci√≥n continua.

### Stack de debugging y testing
![Stack de debugging y testing](diagrams_png/debug_testing_stack.png)
- Para monitoreo de salud y depuraci√≥n avanzada.

### Stack completo (todos los servicios)
![Stack completo (todos los servicios)](diagrams_png/all_services_stack.png)
- Todos los servicios del stack levantados simult√°neamente.

---

**¬øQuieres crear tus propios diagramas o modificar los existentes?**
Consulta el archivo [`docs/DIAGRAMS_INSTRUCTIONS.es.md`](docs/DIAGRAMS_INSTRUCTIONS.es.md) para aprender c√≥mo generar los PNG a partir de los archivos `.mmd` usando Mermaid CLI. 
