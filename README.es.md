<!--
üåê Idioma: Espa√±ol | [English](README.md)
-->

> **Esta documentaci√≥n est√° en espa√±ol. La versi√≥n principal en ingl√©s est√° en [README.md](README.md).**

# My Self-Hosted AI Kit (Kit de IA Auto-hospedado)

Un stack completo de herramientas de Inteligencia Artificial auto-hospedadas usando Docker Compose. Este proyecto incluye Ollama para modelos de lenguaje local, n8n para automatizaci√≥n, Open WebUI para interfaz de chat, y m√°s.

## üöÄ ¬øQu√© incluye este stack?

### Servicios principales:
- **Ollama**: Servidor de modelos de lenguaje local (LLMs)
- **Open WebUI**: Interfaz web moderna para chat con IA
- **n8n**: Plataforma de automatizaci√≥n de flujos de trabajo
- **PostgreSQL**: Base de datos para n8n
- **Qdrant**: Base de datos vectorial para embeddings
- **pgvector**: Extensi√≥n de PostgreSQL para vectores

### Servicios opcionales:
- **Backup autom√°tico**: Respaldo diario de datos (perfil `monitoring`)
- **Herramientas de desarrollo**: Contenedor con utilidades (perfil `dev`)

### Modelos de IA incluidos:
- llama3.2 (modelo base)
- llama3.3 (modelo m√°s avanzado)
- all-minilm (modelo de embeddings)
- deepseek-r1:14b (modelo especializado)
- nomic-embed-text (embeddings de texto)

## üìã Prerrequisitos

### Software necesario:
- **Docker Engine** (no Docker Desktop)
- **Docker Compose**
- **Git** (para clonar el repositorio)

### Hardware recomendado:
- **RAM**: M√≠nimo 8GB, recomendado 16GB+ (optimizado para 96GB)
- **GPU**: NVIDIA con drivers propietarios (optimizado para RTX 5060 Ti)
- **CPU**: M√≠nimo 4 cores, recomendado 8+ cores (optimizado para Ryzen 7 7700)
- **Almacenamiento**: Al menos 50GB libres (los modelos de IA son grandes)

## üõ†Ô∏è Instalaci√≥n

### 1. Clonar el repositorio
```bash
git clone <tu-repositorio>
cd my-selfhosted-ai-kit
```

### 2. Configurar variables de entorno
Crea un archivo `.env` en la ra√≠z del proyecto:
```bash
# Configuraci√≥n de PostgreSQL
POSTGRES_USER=postgres
POSTGRES_PASSWORD=tu_contrase√±a_segura
POSTGRES_DB=n8n

# Configuraci√≥n de n8n
N8N_ENCRYPTION_KEY=tu_clave_de_encriptacion_32_caracteres
N8N_USER_MANAGEMENT_JWT_SECRET=tu_jwt_secret_seguro
```

### 3. Configurar GPU (opcional)
Si tienes GPU NVIDIA y quieres aceleraci√≥n:

```bash
# Instalar nvidia-container-toolkit
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker

# Verificar que funciona
sudo docker run --rm --gpus all nvidia/cuda:12.0.0-base-ubuntu22.04 nvidia-smi
```

## üöÄ Uso

### Perfiles disponibles

El stack incluye diferentes perfiles para optimizar seg√∫n tus necesidades:

#### Perfil b√°sico (CPU):
```bash
docker compose --profile cpu up -d
```

#### Perfil GPU NVIDIA (recomendado para tu RTX 5060 Ti):
```bash
docker compose --profile gpu-nvidia up -d
```

#### Perfil GPU AMD:
```bash
docker compose --profile gpu-amd up -d
```

#### Perfil de desarrollo:
```bash
docker compose --profile dev up -d
```

#### Perfil de monitoreo y respaldos:
```bash
docker compose --profile monitoring up -d
```

#### Perfil de infraestructura (Redis, HAProxy):
```bash
docker compose --profile infrastructure up -d
```

#### Perfil de seguridad (Keycloak, ModSecurity):
```bash
docker compose --profile security up -d
```

#### Perfil de automatizaci√≥n (Watchtower, Sync):
```bash
docker compose --profile automation up -d
```

#### Perfil de CI/CD (Jenkins):
```bash
docker compose --profile ci-cd up -d
```

#### Perfil de testing:
```bash
docker compose --profile testing up -d
```

#### Perfil de debugging:
```bash
docker compose --profile debug up -d
```

#### Combinar m√∫ltiples perfiles:
```bash
# Producci√≥n completa con GPU, monitoreo e infraestructura
docker compose --profile gpu-nvidia --profile monitoring --profile infrastructure up -d

# Desarrollo con herramientas y testing
docker compose --profile cpu --profile dev --profile testing up -d

# Stack completo (¬°cuidado con el uso de recursos!)
docker compose --profile gpu-nvidia --profile monitoring --profile infrastructure --profile security --profile automation up -d
```

### Ver logs en tiempo real:
```bash
docker compose logs -f
```

### Monitorear descarga de modelos:
```bash
./verifica_modelos.sh
```

### Detener todos los servicios:
```bash
docker compose down
```

## üåê Acceso a las aplicaciones

Una vez que los servicios est√©n corriendo, puedes acceder a:

| Servicio | URL | Descripci√≥n |
|----------|-----|-------------|
| **Open WebUI** | http://localhost:3000 | Interfaz web para chat con IA |
| **n8n** | http://localhost:5678 | Automatizaci√≥n de flujos de trabajo |
| **Qdrant** | http://localhost:6333 | Base de datos vectorial |
| **pgvector** | localhost:5433 | PostgreSQL con vectores |
| **Grafana** | http://localhost:3001 | Dashboards de monitoreo (perfil monitoring) |
| **Prometheus** | http://localhost:9090 | M√©tricas del sistema (perfil monitoring) |
| **AlertManager** | http://localhost:9093 | Gesti√≥n de alertas (perfil monitoring) |
| **cAdvisor** | http://localhost:8082 | M√©tricas de contenedores (perfil monitoring) |
| **Node Exporter** | http://localhost:9100 | M√©tricas del host (perfil monitoring) |
| **HAProxy** | http://localhost:80 | Load balancer (perfil infrastructure) |
| **Redis** | localhost:6379 | Cache y sesiones (perfil infrastructure) |
| **Keycloak** | http://localhost:8080 | Autenticaci√≥n centralizada (perfil security) |
| **Jenkins** | http://localhost:8081 | CI/CD Pipeline (perfil ci-cd) |

## üß© ¬øQu√© hace cada perfil y c√≥mo usarlos?

| Perfil           | ¬øQu√© incluye?                                                                 | ¬øCu√°ndo usarlo?                                                                                   | ¬øSe recomienda combinar?         |
|------------------|-------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|----------------------------------|
| **cpu**          | Ollama (CPU)                                                                  | No tienes GPU o quieres ahorrar recursos.                                                         | S√≠, con otros servicios.         |
| **gpu-nvidia**   | Ollama (GPU NVIDIA)                                                           | Tienes GPU NVIDIA y quieres m√°ximo rendimiento en IA.                                             | S√≠, con otros servicios.         |
| **gpu-amd**      | Ollama (GPU AMD)                                                              | Tienes GPU AMD compatible.                                                                        | S√≠, con otros servicios.         |
| **monitoring**   | Prometheus, Grafana, AlertManager, backup autom√°tico                          | Quieres monitoreo, dashboards y respaldos autom√°ticos.                                            | S√≠, con cualquier perfil.        |
| **infrastructure**| Redis, HAProxy                                                               | Necesitas cache o balanceo de carga.                                                              | S√≠, con cualquier perfil.        |
| **security**     | Keycloak (autenticaci√≥n), ModSecurity (WAF)                                   | Quieres autenticaci√≥n centralizada y firewall de aplicaciones web.                                | S√≠, con cualquier perfil.        |
| **automation**   | Watchtower (auto-actualizaci√≥n), Sync                                         | Quieres automatizaci√≥n de actualizaciones y sincronizaci√≥n de datos.                              | S√≠, con cualquier perfil.        |
| **ci-cd**        | Jenkins                                                                       | Necesitas pipelines de integraci√≥n y despliegue continuo.                                         | S√≠, con cualquier perfil.        |
| **testing**      | Test Runner                                                                   | Quieres monitoreo autom√°tico de salud de servicios.                                               | S√≠, con cualquier perfil.        |
| **debug**        | Debug Tools                                                                   | Necesitas herramientas avanzadas de debugging.                                                    | S√≠, con cualquier perfil.        |
| **dev**          | Herramientas de desarrollo (curl, jq, etc.)                                   | Est√°s desarrollando o depurando el stack.                                                         | S√≠, con cualquier perfil.        |

---

### üîë ¬øDebo levantar m√°s de un perfil a la vez?

**¬°S√≠!**  
Cada perfil es modular y **debes combinarlos** seg√∫n tus necesidades.  
Por ejemplo, si solo levantas `security`, tendr√°s Keycloak y ModSecurity, pero **no tendr√°s IA, ni monitoreo, ni automatizaci√≥n**.

#### Ejemplos de combinaciones recomendadas:

- **Desarrollo b√°sico (sin GPU):**
  ```bash
  docker compose --profile cpu --profile dev up -d
  ```
- **IA con GPU y monitoreo:**
  ```bash
  docker compose --profile gpu-nvidia --profile monitoring up -d
  ```
- **Producci√≥n completa (IA, monitoreo, seguridad, infraestructura):**
  ```bash
  docker compose --profile gpu-nvidia --profile monitoring --profile infrastructure --profile security up -d
  ```
- **Solo autenticaci√≥n y seguridad:**
  ```bash
  docker compose --profile security up -d
  ```

### ‚ö†Ô∏è Importante
- **Ning√∫n perfil incluye todo**: Por modularidad, debes combinar los perfiles que necesites.
- **Perfiles de IA (`cpu`, `gpu-nvidia`, `gpu-amd`)**: Solo uno a la vez, seg√∫n tu hardware.
- **Perfiles de servicios**: Puedes combinarlos libremente seg√∫n lo que quieras habilitar.

### üó∫Ô∏è Diagrama visual de perfiles y dependencias

![Diagrama de perfiles y dependencias](diagrams_png/perfiles.png)

### üñºÔ∏è Versi√≥n en imagen

![Diagrama de perfiles y dependencias](diagrams_png/perfiles.png)

### üóíÔ∏è Leyenda de colores del diagrama

- **L√≠neas azules**: Conexiones desde el perfil `cpu`
- **L√≠neas verdes**: Conexiones desde el perfil `gpu-nvidia`
- **L√≠neas naranjas**: Conexiones desde el perfil `gpu-amd`
- **L√≠neas moradas**: Servicios de monitoreo (`monitoring`)
- **L√≠neas rojas**: Servicios de seguridad (`security`)
- **L√≠neas marrones**: Servicios de infraestructura (`infrastructure`)
- **L√≠neas celestes**: Servicios de automatizaci√≥n (`automation`)
- **L√≠neas gris oscuro**: Servicios de CI/CD (`ci-cd`)
- **L√≠neas verde lima**: Servicios de testing (`testing`)
- **L√≠neas rosas**: Servicios de debugging (`debug`)
- **L√≠neas amarillas**: Herramientas de desarrollo (`dev`)

---

## üìä Ejemplos visuales de stacks t√≠picos

A continuaci√≥n se muestran ejemplos visuales de combinaciones de perfiles para distintos escenarios de uso. Los diagramas fuente (.mmd) est√°n en la carpeta `diagrams_mmd/` y los PNG en `diagrams_png/`.

### Stack m√≠nimo para desarrollo
![Stack m√≠nimo para desarrollo](diagrams_png/dev_stack_minimal.png)
- Solo los servicios esenciales para desarrollo local sin GPU.

### Stack de producci√≥n completo
![Stack de producci√≥n completo](diagrams_png/prod_stack_full.png)
- Incluye IA con GPU, monitoreo, seguridad e infraestructura.

### Solo autenticaci√≥n y seguridad
![Solo autenticaci√≥n y seguridad](diagrams_png/security_stack.png)
- Para cuando solo quieres levantar Keycloak y ModSecurity.

### IA con GPU y monitoreo
![IA con GPU y monitoreo](diagrams_png/gpu_monitoring_stack.png)
- Para pruebas de rendimiento y observabilidad.

### Stack de automatizaci√≥n y CI/CD
![Stack de automatizaci√≥n y CI/CD](diagrams_png/automation_cicd_stack.png)
- Para flujos autom√°ticos y pipelines de integraci√≥n continua.

### Stack de debugging y testing
![Stack de debugging y testing](diagrams_png/debug_testing_stack.png)
- Para monitoreo de salud y depuraci√≥n avanzada.

### Stack completo (todos los servicios)
![Stack completo (todos los servicios)](diagrams_png/all_services_stack.png)
- Todos los servicios del stack levantados simult√°neamente.

---

**¬øQuieres crear tus propios diagramas o modificar los existentes?**
Consulta el archivo [`DIAGRAMS_INSTRUCTIONS.es.md`](DIAGRAMS_INSTRUCTIONS.es.md) para aprender c√≥mo generar los PNG a partir de los archivos `.mmd` usando Mermaid CLI. 